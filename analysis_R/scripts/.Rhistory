topic_classfication %>%
mutate(overall_error_rate = mean(MISS_binary)) %>%
group_by(new_topic, run) %>%
mutate(errorrate = summarise(mean(MISS_binary) - overall_error_rate))
topic_classfication %>%
mutate(overall_error_rate = mean(MISS_binary)) %>%
group_by(new_topic, run) %>%
summarise(mean(MISS_binary) - overall_error_rate)
# Merging topics with classification report and simplifying df
topic_classfication <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classfication %>%
mutate(overall_error_rate = mean(MISS_binary)) %>%
group_by(new_topic, run) %>%
summarise(mean(MISS_binary) - mean(overall_error_rate))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse)
# Chunk 2
# Classification report (= classf_report_jonf)
read_plus <- function(flnm) {
read_csv(flnm) %>%
mutate(filename = flnm)
}
classf_report_jonf <- list.files(path = "/Users/wibe/Desktop/CogSci/Bachelor thesis/bachelor_thesis/analysis_R/data/jonfd_electra-small-nordic", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
# Topics (= topics)
topics <- read_csv("/Users/wibe/Desktop/CogSci/Bachelor thesis/bachelor_thesis/analysis_R/data/BerTopic/sub_groups_07112022.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
# Chunk 3
# Creating a numeric variable for miss/true
classf_report_jonf['MISS_binary'] <- ifelse(classf_report_jonf$Misclassification == "TRUE", 1, 0)
# Chunk 4
classf_report_jonf %>%
group_by(filename) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
# Chunk 5
#Overall error rate
mean_overall <- classf_report_jonf %>%
summarise("over_all_error_rate" = mean(MISS_binary))
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
View(topic_classf)
# Merging topics with classification report and minimizing df
length(topics$language)
# Merging topics with classification report and minimizing df
length(classf_report_jonf$`Predicted Labels`)
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run) %>%
topic_classf[complete.cases(topic_classf), ]
topic_classf[complete.cases(topic_classf), ]
view(topic_classf[complete.cases(topic_classf), ])
length(view(topic_classf[complete.cases(topic_classf), ]))
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run) %>%
topic_classf[complete.cases(topic_classf), ]
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
topic_classf[complete.cases(topic_classf), ] %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run) %>%
topic_classfication %>%
mutate(overall_error_rate = mean(MISS_binary)) %>%
group_by(new_topic, run) %>%
summarise(mean(MISS_binary) - mean(overall_error_rate))
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
topic_classf[complete.cases(topic_classf), ] %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf <- topic_classf[complete.cases(topic_classf), ] # remove NA rows (REMEMBER DELETE THIS)
topic_classf %>%
group_by(run, new_topic) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
view(topic_classf %>%
group_by(run, new_topic) %>%
summarise("error_rate_per_run" = mean(MISS_binary)))
table(topic_classf$run)
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_subtracted_from_error_rate_for_all_runs_on_same_topic" = error_rate_per_topic_across_runs - error_rate_per_run)
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_subtracted_from_error_rate_for_all_runs_on_same_topic" = error_rate_per_run - error_rate_per_topic_across_runs)
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_subtracted_from_error_rate_for_all_runs_on_same_topic" = error_rate_per_topic_across_runs - mean(error_rate_per_run))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_subtracted_from_error_rate_for_all_runs_on_same_topic" = error_rate_per_topic_across_runs - mean(MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_subtracted_from_error_rate_for_all_runs_on_same_topic" = error_rate_per_topic_across_runs - mean(topic_classf$MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" = error_rate_per_topic_across_runs - mean(topic_classf$MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" =  mean(topic_classf$MISS_binary) - error_rate_per_topic_across_runs)
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" = error_rate_per_topic_across_runs - mean(topic_classf$MISS_binary))
setwd("~/Desktop/CogSci/Bachelor thesis/bachelor_thesis/analysis_R/scripts")
# Classification report (= classf_report_jonf)
read_plus <- function(flnm) {
read_csv(flnm) %>%
mutate(filename = flnm)
}
classf_report_jonf <- list.files(path = "data/jonfd_electra-small-nordic", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
# Topics (= topics)
topics <- read_csv("data/BerTopic/sub_groups_07112022.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
# Topics (= topics)
topics <- read_csv("data/BerTopic/sub_groups_07112022.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
# Classification report (= classf_report_jonf)
read_plus <- function(flnm) {
read_csv(flnm) %>%
mutate(filename = flnm)
}
classf_report_jonf <- list.files(path = "/data/jonfd_electra-small-nordic", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
# Topics (= topics)
topics <- read_csv("/data/BerTopic/sub_groups_07112022.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
setwd("~/Desktop/CogSci/Bachelor thesis/bachelor_thesis/analysis_R/scripts")
# Classification report (= classf_report_jonf)
read_plus <- function(flnm) {
read_csv(flnm) %>%
mutate(filename = flnm)
}
classf_report_jonf <- list.files(path = "../data/jonfd_electra-small-nordic", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
# Topics (= topics)
topics <- read_csv("../data/BerTopic/sub_groups_07112022.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
#Overall error rate
mean_overall <- classf_report_jonf %>%
summarise("over_all_error_rate" = mean(MISS_binary))
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse)
# Chunk 2
# Classification report (= classf_report_jonf)
read_plus <- function(flnm) {
read_csv(flnm) %>%
mutate(filename = flnm)
}
classf_report_jonf <- list.files(path = "../data/jonfd_electra-small-nordic", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
# Topics (= topics)
topics <- read_csv("../data/BerTopic/sub_groups_07112022.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
# Chunk 3
# Creating a numeric variable for miss/true
classf_report_jonf['MISS_binary'] <- ifelse(classf_report_jonf$Misclassification == "TRUE", 1, 0)
# Chunk 4
classf_report_jonf %>%
group_by(filename) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
#Overall error rate
mean_overall <- classf_report_jonf %>%
summarise("over_all_error_rate" = mean(MISS_binary))
#Overall error rate
mean_overall <- classf_report_jonf %>%
summarise("over_all_error_rate" = mean(MISS_binary))
#Overall error rate
mean_overall <- classf_report_jonf %>%
summarise("over_all_error_rate" = mean(MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" = error_rate_per_topic_across_runs - mean(MISS_binary))
view(topic_classf %>%
group_by(run, topics))
View(topic_classf)
view(topic_classf %>%
group_by(run, new_topic))
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" = error_rate_per_topic_across_runs - mean(MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" = error_rate_per_topic_across_runs - mean(topic_classf$MISS_binary))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" = error_rate_per_topic_across_runs - mean(topic_classf$MISS_binary))
# Classification report (= classf_report_jonf)
read_plus <- function(flnm) {
read_csv(flnm) %>%
mutate(filename = flnm)
}
classf_report_jonf <- list.files(path = "../data/jonfd_electra-small-nordic", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
view(read_csv("/Users/wibe/Desktop/CogSci/Bachelor thesis/bachelor_thesis/analysis_R/data/jonfd_electra-small-nordic/df_classification_report1.csv"))
# Topics (= topics)
topics <- read_csv("../data/BerTopic/*.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
setwd("~/Desktop/CogSci/Bachelor thesis/bachelor_thesis/analysis_R/scripts")
# Topics (= topics)
topics <- read_csv("../data/BerTopic/*.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
# Topics (= topics)
topics <- read_csv("../data/BerTopic/sub_groups_14112022.csv") %>%
rename(Text = original_tweet) %>%
distinct(Text, .keep_all = TRUE) # remove duplicate rows
# Topics (= topics)
test <- read_csv("../data/BerTopic/sub_groups_14112022.csv")
# Topics (= topics)
rm(test)
classf_report_jonf %>%
group_by(filename) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
# Creating a numeric variable for miss/true
classf_report_jonf['MISS_binary'] <- ifelse(classf_report_jonf$Misclassification == "TRUE", 1, 0)
classf_report_jonf %>%
group_by(filename) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
#Overall error rate
classf_report_jonf %>%
summarise("over_all_error_rate" = mean(MISS_binary))
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf, topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
View(topic_classf)
# Topics (= topics)
topics <- read_csv("../data/BerTopic/sub_groups_14112022.csv") %>%
rename(Text = original_tweet)
# Merging topics with classification report and minimizing df
topic_classf <- merge(topics, classf_report_jonf, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
View(topic_classf)
# Merging topics with classification report and minimizing df
topic_classf <- merge(topics, classf_report_jonf, by = "Text") %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
View(topic_classf)
# Merging topics with classification report and minimizing df
topic_classf <- merge(topics, classf_report_jonf, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
View(classf_report_jonf)
View(topics)
View(classf_report_jonf)
# Topics (= topics)
topics <- read_csv("../data/BerTopic/sub_groups_14112022.csv") %>%
rename(Text = original_tweet)
# Creating a numeric variable for miss/true
classf_report_jonf['MISS_binary'] <- ifelse(classf_report_jonf$Misclassification == "TRUE", 1, 0)
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
View(topic_classf)
View(topics)
View(classf_report_jonf)
topic_classf <- topic_classf[complete.cases(topic_classf), ]
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
table(is.na(topic_classf))
table(is.na(topic_classf$new_topic))
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf <- topic_classf[complete.cases(topic_classf), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
# Error rates per topic across runs
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run))
ggplot(topics, aes(new_topic))
ggplot(topics, aes(new_topic))+
geom_bar
ggplot(topics, aes(new_topic))+
geom_bar()
ggplot(topics, aes(new_topic))+
geom_bar()+
theme_bw()
ggplot(topics, aes(new_topic, fill = language))+
geom_bar()+
theme_bw()
# Creating a numeric variable for miss/true
classf_report_jonf['MISS_binary'] <- ifelse(classf_report_jonf$Misclassification == "TRUE", 1, 0)
classf_report_jonf %>%
group_by(filename) %>%
summarise("error_rate_per_run" = mean(MISS_binary))
### Overall error rate over all runs
```{r}
#Overall error rate
classf_report_jonf %>%
summarise("over_all_error_rate" = mean(MISS_binary))
```
# Merging topics with classification report and minimizing df
topic_classf <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf <- topic_classf[complete.cases(topic_classf), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
# Error rates per topic across runs
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run))
# Seeing how many topics are in each category after merging
ggplot(topic_classf, aes(new_topic))+
geom_bar()+
theme_bw()
# Seeing how many topics are in each category after merging
ggplot(topic_classf, aes(new_topic))+
geom_bar()+
theme_bw()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic)) %>%
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run, new_topic) %>%
ggplot(aes(new_topic)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
summarise(distinct(run)) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
summarise(distinct(run,.keep_all=T)) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
summarise(distinct(run,.keep_all=F)) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic/10, fill = run)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic)) +
geom_bar()
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()+
geom_title("divide by 10")
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()+
geom_labs(title = "divide by 10")
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()+
labs(title = "divide by 10")
# Seeing how many topics are in each category after merging
topic_classf %>%
group_by(run) %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()+
labs(title = "Number of entries per topic after merging with classificatio report", subtitle = "Divide y-axis by 10")
# Seeing how many topics are in each category after merging
topic_classf %>%
ggplot(aes(new_topic, fill = run)) +
geom_bar()+
labs(title = "Number of entries per topic after merging with classification report", subtitle = "NB: Divide y-axis by 10")
# Error rates per topic across runs
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run))
topic_classf %>%
group_by(new_topic, run) %>%
summarise("error_rate_per_run" = mean(MISS_binary)) %>%
summarise("error_rate_per_topic_across_runs" = mean(error_rate_per_run)) %>%
summarise("error_rates_per_topic_relative_to_overall_error_rate_pr_topic" = error_rate_per_topic_across_runs - mean(topic_classf$MISS_binary))
topic_classf %>%
group_by(run, new_topic) %>%
summarise("error_rate_per_run_across_all_topics" = mean(MISS_binary)) #%>%
topic_classf %>%
group_by(new_topic) %>%
summarise("average_error" = mean(MISS_binary)) %>%
ggplot(aes(x = new_topic, y = average_error))+
geom_point() +
ggtitle("Box Plot")
topic_classf %>%
group_by(new_topic) %>%
summarise("average_error" = mean(MISS_binary)) %>%
ggplot(aes(x = new_topic, y = average_error))+
geom_point() +
ggtitle("Box Plot")
#Basic boxplot
ggplot(topic_classf, aes(x=new_topic, y=MISS_binary))+
geom_boxplot(width = 0.5) +
ggtitle("Box Plot")
#Basic boxplot
ggplot(topic_classf, aes(x=new_topic, y=MISS_binary))+
geom_boxplot(width = 0.5) +
ggtitle("Box Plot")
#Basic boxplot
ggplot(topic_classf, aes(x=as.factor(new_topic), y=MISS_binary))+
geom_boxplot(width = 0.5) +
ggtitle("Box Plot")
#Basic boxplot
ggplot(topic_classf, aes(x=as.factor(new_topic), y=`Predicted Labels`))+
geom_boxplot(width = 0.5) +
ggtitle("Box Plot")
