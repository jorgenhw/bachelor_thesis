---
title: "Model comparison"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse,devtools,rethinking)
```

# LOADING DATA

```{r}
######## LOADING CLASSIFICATION REPORT #################

# Function for loading multiple files
read_plus <- function(flnm) {
    read_csv(flnm) %>% 
        mutate(filename = flnm)
}

# jonfd_electra-small-nordic
classf_report_jonf <- list.files(path = "../data/jonfd_electra-small-nordic", pattern = "*.csv", 
               full.names = T) %>% 
    map_df(~read_plus(.))
classf_report_jonf['MISS_binary'] <- ifelse(classf_report_jonf$Misclassification == "TRUE", 1, 0) 

# vestinn/ScandiBERT
classf_report_vestin <- list.files(path = "../data/vestinn_ScandiBERT", pattern = "*.csv", 
               full.names = T) %>% 
    map_df(~read_plus(.))
classf_report_vestin['MISS_binary'] <- ifelse(classf_report_vestin$Misclassification == "TRUE", 1, 0) 

# aelectra
classf_report_aelectra <- list.files(path = "../data/aelectra", pattern = "*.csv", 
               full.names = T) %>% 
    map_df(~read_plus(.))
classf_report_aelectra['MISS_binary'] <- ifelse(classf_report_aelectra$Misclassification == "TRUE", 1, 0) 

# xlm-roberta-base
classf_report_XLM_base <- list.files(path = "../data/xlm-roberta-base", pattern = "*.csv", 
               full.names = T) %>% 
    map_df(~read_plus(.))
classf_report_XLM_base['MISS_binary'] <- ifelse(classf_report_XLM_base$Misclassification == "TRUE", 1, 0)

# xlm_roberta_large
classf_report_XLM_large <- list.files(path = "../data/xlm_roberta_large", pattern = "*.csv", 
               full.names = T) %>% 
    map_df(~read_plus(.))
classf_report_XLM_large['MISS_binary'] <- ifelse(classf_report_XLM_large$Misclassification == "TRUE", 1, 0)

########## LOADING TOPICS ###############
topics <- read_csv("../data/BerTopic/sub_groups_14112022.csv") %>% 
  rename(Text = original_tweet) 
```


# MERGING CLASSIFICATION REPORTS WITH TOPICS
```{r}
# JONF: Merging topics with classification report and minimizing df 
topic_classf_JONF <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>% 
  rename(run = filename) %>% 
  select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_JONF <- topic_classf_JONF[complete.cases(topic_classf_JONF), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_JONF$model_ <- 1

# SCANDIBERT: Merging topics with classification report and minimizing df 
topic_classf_SCANDIBERT <- merge(classf_report_vestin,topics, by = "Text", all.x = T, all.y = F) %>% 
  rename(run = filename) %>% 
  select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_SCANDIBERT <- topic_classf_SCANDIBERT[complete.cases(topic_classf_SCANDIBERT), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_SCANDIBERT$model_ <- 2

# AELECTRA: Merging topics with classification report and minimizing df 
topic_classf_AELECTRA <- merge(classf_report_aelectra,topics, by = "Text", all.x = T, all.y = F) %>% 
  rename(run = filename) %>% 
  select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_AELECTRA <- topic_classf_AELECTRA[complete.cases(topic_classf_AELECTRA), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_AELECTRA$model_ <- 3

# XLM_BASE: Merging topics with classification report and minimizing df 
topic_classf_XLM_BASE <- merge(classf_report_XLM_base,topics, by = "Text", all.x = T, all.y = F) %>% 
  rename(run = filename) %>% 
  select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_BASE <- topic_classf_XLM_BASE[complete.cases(topic_classf_XLM_BASE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_BASE$model_ <- 4

# XLM_LARGE: Merging topics with classification report and minimizing df 
topic_classf_XLM_LARGE <- merge(classf_report_XLM_large,topics, by = "Text", all.x = T, all.y = F) %>% 
  rename(run = filename) %>% 
  select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_LARGE <- topic_classf_XLM_LARGE[complete.cases(topic_classf_XLM_LARGE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_LARGE$model_ <- 5

# combining
all_models <- rbind(topic_classf_XLM_LARGE, topic_classf_XLM_BASE, topic_classf_AELECTRA, topic_classf_SCANDIBERT, topic_classf_JONF)
```

# GETTING ERROR RATES FOR EACH MODEL
```{r}
error_rate_per_run_per_topic <- all_models %>% 
  group_by(new_topic, run, model_) %>% 
  summarise("error_rate_per_run_per_topic" = mean(MISS_binary))

error_rate_per_run_across_topics <- all_models %>% 
  group_by(run, model_) %>% 
  summarise("error_rate_per_run_across_topics" = mean(MISS_binary))

tress <- merge(error_rate_per_run_per_topic, error_rate_per_run_across_topics, by = "run", all.x = T, all.y = F)

quatro <- tress %>% 
  mutate(diff = error_rate_per_run_per_topic - error_rate_per_run_across_topics)

singo <- quatro %>% 
  #filter(new_topic==3) %>% 
  rename(ourmodel = `model_.x`) %>% 
  rename(difference = diff) %>% 
  select(run, new_topic, ourmodel,difference)

final <- singo %>% 
  select(difference, ourmodel)
```

```{r}
final <-  singo %>% 
  select(ourmodel,difference, new_topic)

func_TEMP <- function(topic){
  func_df <- final %>% 
    filter(new_topic == topic)
  
  func_model <- ulam(
    alist(
        difference ~ dnorm(mu, sigma),
        mu <- a[ourmodel],
        a[ourmodel] ~ dnorm(0.40, 0.15) ,
        sigma ~ dexp(2) 
    ), data = func_df, chains = 4, cores = 4)
  
  func_precis <- precis(func_model, depth = 2)
  
  return(func_precis)
}

list_precis <- lapply(list(-1,0,1,2,3,4,5,6,7,8,9), func_TEMP)


###### MODEL #######
# m1 <- ulam(
#     alist(
#         niels ~ dnorm(mu, sigma),
#         mu <- a[ourmodel],
#         a[ourmodel] ~ dnorm(0.40, 0.15) ,
#         sigma ~ dexp(2) 
#     ), data = final, chains = 4, cores = 4)
# 
# precis(m1, depth =2)
# plot(coeftab(m1),by.model=TRUE)


```

```{r}
### COMPARING THE MEANS WITHIN MODEL
pacman::p_load(tidybayes.rethinking)

func_TEMP <- function(topic){
  func_df <- final %>% 
    filter(new_topic == topic)
  
  func_model <- ulam(
    alist(
        difference ~ dnorm(mu, sigma),
        mu <- a[ourmodel],
        a[ourmodel] ~ dnorm(0.40, 0.15) ,
        sigma ~ dexp(2) 
    ), data = func_df, chains = 4, cores = 4)
  
  func_precis <- precis(func_model, depth = 2)
  
  return(list(func_precis, func_model))
}

output_list <- func_TEMP(3)

temp_df <-  final %>% 
  filter(new_topic == 3)

temp_model <- ulam(
    alist(
        difference ~ dnorm(mu, sigma),
        mu <- a[ourmodel],
        a[ourmodel] ~ dnorm(0.40, 0.15) ,
        sigma ~ dexp(2) 
    ), data = temp_df, chains = 4, cores = 4)

precis(temp_model, depth = 2)

post <- extract.samples(temp_model)

post$diff_12 <- post$a[,1] - post$a[,2]
post$diff_13 <- post$a[,1] - post$a[,3]
post$diff_14 <- post$a[,1] - post$a[,4]
post$diff_15 <- post$a[,1] - post$a[,5]
post$diff_16 <- post$a[,1] - post$a[,6]
post$diff_17 <- post$a[,1] - post$a[,7]
post$diff_18 <- post$a[,1] - post$a[,8]
post$diff_19 <- post$a[,1] - post$a[,9]
post$diff_23 <- post$a[,2] - post$a[,3]
post$diff_24 <- post$a[,2] - post$a[,4]
post$diff_25 <- post$a[,2] - post$a[,5]
post$diff_26 <- post$a[,2] - post$a[,6]
post$diff_27 <- post$a[,2] - post$a[,7]
post$diff_28 <- post$a[,2] - post$a[,8]
post$diff_29 <- post$a[,2] - post$a[,9]
post$diff_34 <- post$a[,3] - post$a[,4]
post$diff_35 <- post$a[,3] - post$a[,5]
post$diff_36 <- post$a[,3] - post$a[,6]
post$diff_37 <- post$a[,3] - post$a[,7]
post$diff_38 <- post$a[,3] - post$a[,8]
post$diff_39 <- post$a[,3] - post$a[,9]
post$diff_45 <- post$a[,4] - post$a[,5]
post$diff_46 <- post$a[,4] - post$a[,6]
post$diff_47 <- post$a[,4] - post$a[,7]
post$diff_48 <- post$a[,4] - post$a[,8]
post$diff_49 <- post$a[,4] - post$a[,9]
post$diff_56 <- post$a[,5] - post$a[,6]
post$diff_57 <- post$a[,5] - post$a[,7]
post$diff_58 <- post$a[,5] - post$a[,8]
post$diff_59 <- post$a[,5] - post$a[,9]
post$diff_67 <- post$a[,6] - post$a[,7]
post$diff_68 <- post$a[,6] - post$a[,8]
post$diff_69 <- post$a[,6] - post$a[,9]
post$diff_78 <- post$a[,7] - post$a[,8]
post$diff_79 <- post$a[,7] - post$a[,9]
post$diff_89 <- post$a[,8] - post$a[,9]


precis( post , depth=2 )



plot( precis( post , depth=2))
```

```{r}
as_tibble(post[3:length(post)])%>% 
  select(diff_12, diff_13, diff_14, diff_15, diff_23, diff_24, diff_25, diff_34, diff_35, diff_45) %>% 
  pivot_longer(cols = "diff_12":"diff_45", names_to = "model", values_to = "contrast") %>% 
ggplot(aes(x = contrast, y = model)) +
  stat_halfeye()
```

```{r}
simulated_df <- tibble("m1" = rnorm(1000, post$a[,1], post$sigma))
simulated_df$m2 <- rnorm(1000, post$a[,2], post$sigma)
simulated_df$m3 <- rnorm(1000, post$a[,3], post$sigma)
simulated_df$m4 <- rnorm(1000, post$a[,4], post$sigma)
simulated_df$m5 <- rnorm(1000, post$a[,5], post$sigma)

simulated_df$m1m2 <- simulated_df$m1-simulated_df$m2
simulated_df$m1m3 <- simulated_df$m1-simulated_df$m3
simulated_df$m1m4 <- simulated_df$m1-simulated_df$m4
simulated_df$m1m5 <- simulated_df$m1-simulated_df$m5
simulated_df$m2m3 <- simulated_df$m2-simulated_df$m3
simulated_df$m2m4 <- simulated_df$m2-simulated_df$m4
simulated_df$m2m5 <- simulated_df$m2-simulated_df$m5
simulated_df$m3m4 <- simulated_df$m3-simulated_df$m4
simulated_df$m3m5 <- simulated_df$m3-simulated_df$m5
simulated_df$m4m5 <- simulated_df$m4-simulated_df$m5

simulated_df %>% 
  pivot_longer(cols = "m1m2":"m4m5", names_to = "model_diff", values_to = "contrast") %>% 
  ggplot(aes(x = contrast, y = model_diff)) +
  stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") 
```


```{r}
samples <- extract.samples(temp_model, n=1e4)

# so PI and HPDI practically ends up being the same. This is true for posterior distributions that are kind of normally distributed
PI(samples$a[,1], prob = 0.5)
HPDI(samples$a[,1], prob = 0.5)
```






















