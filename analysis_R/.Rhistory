getwd()
knitr::opts_chunk$set(echo = TRUE)
pcaman::p_load(tidyverse)
pacman::p_load(tidyverse)
1:9
path <- paste("../data/df_classification_report", 0, ".csv")
df <- read_csv(path)
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$run <- 0
for (i in 1:9) {
path <- paste("../data/df_classification_report", i, ".csv")
df_temp <- read_csv(path)
df_temp$run <- i
df <- rbind(df, df_temp)
}
View(df)
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$run <- 0
rbind(df, df)
for (i in 1:9) {
path <- paste("../data/df_classification_report", i, ".csv")
df_temp <- read_csv(path)
df_temp$run <- i
df <- rbind(df, df_temp)
}
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$run <- 0
for (i in 1:9) {
path <- paste("../data/df_classification_report", i, ".csv", sep = "")
df_temp <- read_csv(path)
df_temp$run <- i
df <- rbind(df, df_temp)
}
View(df)
as.binary(df$Misclassification)
ifelse(df$Misclassification == "TRUE", 1, 0)
df$mis_binary <- ifelse(df$Misclassification == "TRUE", 1, 0)
df %>%
group_by(run) %>%
summarise("over_all_error_rate" = mean(mis_binary))
View(df)
df$positive_true <- ifelse(df$`True Labels` == "positive", 1, 0)
View(df)
df %>%
group_by(run) %>%
summarise("over_all_error_rate" = mean(mis_binary), "count" = n())
df$mis_binary <- ifelse(df$Misclassification == "TRUE", 1, 0)
df$positive_true <- ifelse(df$`True Labels` == "positive", 1, 0)
df$neutral_true <- ifelse(df$`True Labels` == "neutral", 1, 0)
df$negative_true <- ifelse(df$`True Labels` == "negative", 1, 0)
View(df)
df$positive_true <- ifelse(df$`Predicted Labels` == "positive", 1, 0)
df$neutral_true <- ifelse(df$`Predicted Labels` == "neutral", 1, 0)
df$negative_true <- ifelse(df$`Predicted Labels` == "negative", 1, 0)
df$positive_pred <- ifelse(df$`Predicted Labels` == "positive", 1, 0)
df$neutral_pred <- ifelse(df$`Predicted Labels` == "neutral", 1, 0)
df$negative_pred <- ifelse(df$`Predicted Labels` == "negative", 1, 0)
df %>%
group_by(run) %>%
summarise("over_all_error_rate" = mean(mis_binary), "count" = n(), "precision" = sum(ifelse((positive_pred == 1) & (mis_binary == 1), 1, 0))/sum(positive_pred))
df %>%
group_by(run) %>%
summarise("over_all_error_rate" = mean(mis_binary), "count" = n(), "precision_pos" = sum(ifelse((positive_pred == 1) & (mis_binary == 1), 1, 0))/sum(positive_pred), "precision_neu" = sum(ifelse((neutral_pred == 1) & (mis_binary == 1), 1, 0))/sum(neutral_pred), "precision_neg" = sum(ifelse((negative_pred == 1) & (mis_binary == 1), 1, 0))/sum(negative_pred))
df %>%
group_by(run) %>%
summarise("over_all_error_rate" = mean(mis_binary))
df %>%
group_by(`Predicted Labels`) %>%
summarise("within_tweet_error_rate" = mean(mis_binary))
df %>%
group_by("...1") %>%
summarise("within_tweet_error_rate" = mean(mis_binary))
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary))
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary)) %>%
ggplot(aes(x = within_tweet_error_rate)) +
geom_histogram()
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary)) %>%
ggplot(aes(x = within_tweet_error_rate)) +
geom_histogram() +
title(main = "Are predictions different within model?", sub = "0 is always predicted wrong, 1 is always predicted correct, everything in between varies between instances of Ælæctra")
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary)) %>%
ggplot(aes(x = within_tweet_error_rate)) +
geom_histogram() +
ggtitle(label = "Are predictions different within model?", subtitle = "0 is always predicted wrong, 1 is always predicted correct, everything in between varies between instances of Ælæctra")
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary)) %>%
ggplot(aes(x = within_tweet_error_rate)) +
geom_histogram() +
ggtitle(label = "Are predictions different within model?", subtitle = "0 is always predicted wrong, 1 is always predicted correct, everything in between /n varies between instances of Ælæctra")
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary)) %>%
ggplot(aes(x = within_tweet_error_rate)) +
geom_histogram() +
ggtitle(label = "Are predictions different within model?", subtitle = "0 is always predicted wrong, 1 is always predicted correct, everything in between //n varies between instances of Ælæctra")
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary)) %>%
ggplot(aes(x = within_tweet_error_rate)) +
geom_histogram() +
ggtitle(label = "Are predictions different within model?", subtitle = "0 is always predicted wrong, 1 is always predicted correct, everything in between varies between instances of Ælæctra")
df %>%
group_by(...1) %>%
summarise("within_tweet_error_rate" = mean(mis_binary)) %>%
ggplot(aes(x = within_tweet_error_rate)) +
geom_histogram() +
ggtitle(label = "Are predictions different within model?", subtitle = "0 is always predicted wrong, 1 is always predicted correct, everything in between varies between instances of Ælæctra")
df %>%
group_by(run) %>%
summarise("over_all_error_rate" = mean(mis_binary)) %>%
ungroup()
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse)
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$run <- 0
df$model <- "electra-danish"
for (i in 1:9) {
path <- paste("../data/df_classification_report", i, ".csv", sep = "")
df_temp <- read_csv(path)
df_temp$run <- i
df$model <- "electra-danish"
df <- rbind(df, df_temp)
}
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$run <- 0
df$model <- "electra-danish"
for (i in 1:9) {
path <- paste("../data/df_classification_report", i, ".csv", sep = "")
df_temp <- read_csv(path)
df_temp$run <- i
df$model <- "electra-danish"
df <- rbind(df, df_temp)
}
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$model <- "electra-danish"
View(df)
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$run <- 0
View(df)
df$model <- "electra-danish"
for (i in 1:9) {
path <- paste("../data/df_classification_report", i, ".csv", sep = "")
df_temp <- read_csv(path)
df_temp$run <- i
df$model <- "electra-danish"
df <- rbind(df, df_temp)
}
path <- paste("../data/df_classification_report", 0, ".csv", sep = "")
df <- read_csv(path)
df$run <- 0
df$model <- "electra-danish"
for (i in 1:9) {
path <- paste("../data/df_classification_report", i, ".csv", sep = "")
df_temp <- read_csv(path)
df_temp$run <- i
df_temp$model <- "electra-danish"
df <- rbind(df, df_temp)
}
getwd()
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse,devtools,rethinking)
######## LOADING CLASSIFICATION REPORT #################
# Function for loading multiple files
read_plus <- function(flnm) {
read_csv(flnm) %>%
mutate(filename = flnm)
}
# jonfd_electra-small-nordic
classf_report_jonf <- list.files(path = "../data/jonfd_electra-small-nordic", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
classf_report_jonf['MISS_binary'] <- ifelse(classf_report_jonf$Misclassification == "TRUE", 1, 0)
# vestinn/ScandiBERT
classf_report_vestin <- list.files(path = "../data/vestinn_ScandiBERT", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
classf_report_vestin['MISS_binary'] <- ifelse(classf_report_vestin$Misclassification == "TRUE", 1, 0)
# aelectra
classf_report_aelectra <- list.files(path = "../data/aelectra", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
classf_report_aelectra['MISS_binary'] <- ifelse(classf_report_aelectra$Misclassification == "TRUE", 1, 0)
# xlm-roberta-base
classf_report_XLM_base <- list.files(path = "../data/xlm-roberta-base", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
classf_report_XLM_base['MISS_binary'] <- ifelse(classf_report_XLM_base$Misclassification == "TRUE", 1, 0)
# xlm_roberta_large
classf_report_XLM_large <- list.files(path = "../data/xlm_roberta_large", pattern = "*.csv",
full.names = T) %>%
map_df(~read_plus(.))
classf_report_XLM_large['MISS_binary'] <- ifelse(classf_report_XLM_large$Misclassification == "TRUE", 1, 0)
########## LOADING TOPICS ###############
topics <- read_csv("../data/BerTopic/sub_groups_14112022.csv") %>%
rename(Text = original_tweet)
# JONF: Merging topics with classification report and minimizing df
topic_classf_JONF <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_JONF <- topic_classf_JONF[complete.cases(topic_classf_JONF), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_JONF$model_ <- 2
# SCANDIBERT: Merging topics with classification report and minimizing df
topic_classf_SCANDIBERT <- merge(classf_report_vestin,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_SCANDIBERT <- topic_classf_SCANDIBERT[complete.cases(topic_classf_SCANDIBERT), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_SCANDIBERT$model_ <- 2
# AELECTRA: Merging topics with classification report and minimizing df
topic_classf_AELECTRA <- merge(classf_report_aelectra,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_AELECTRA <- topic_classf_AELECTRA[complete.cases(topic_classf_AELECTRA), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_AELECTRA$model_ <- 3
# XLM_BASE: Merging topics with classification report and minimizing df
topic_classf_XLM_BASE <- merge(classf_report_XLM_base,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_BASE <- topic_classf_XLM_BASE[complete.cases(topic_classf_XLM_BASE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_BASE$model_ <- 4
# XLM_LARGE: Merging topics with classification report and minimizing df
topic_classf_XLM_LARGE <- merge(classf_report_XLM_large,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_LARGE <- topic_classf_XLM_LARGE[complete.cases(topic_classf_XLM_LARGE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_LARGE$model_ <- 5
# combining
all_models <- rbind(topic_classf_XLM_LARGE, topic_classf_XLM_BASE, topic_classf_AELECTRA, topic_classf_SCANDIBERT, topic_classf_JONF)
error_rate_per_run_per_topic <- all_models %>%
group_by(new_topic, run, model_) %>%
summarise("error_rate_per_run_per_topic" = mean(MISS_binary))
error_rate_per_run_across_topics <- all_models %>%
group_by(run, model_) %>%
summarise("error_rate_per_run_across_topics" = mean(MISS_binary))
tress <- merge(error_rate_per_run_per_topic, error_rate_per_run_across_topics, by = "run", all.x = T, all.y = F)
quatro <- tress %>%
mutate(diff = error_rate_per_run_per_topic - error_rate_per_run_across_topics)
# uno <- topic_classf %>%
#   group_by(new_topic, run) %>%
#   summarise("error_rate_per_run_per_topic" = mean(MISS_binary))
#
# dos <- topic_classf %>%
#   group_by(run) %>%
#   summarise("error_rate_per_run_across_topics" = mean(MISS_binary))
#
# tress <- merge(uno, dos, by ="run", all.x = T, all.y = F)
#
# quatro <- tress %>%
#   mutate(diff = error_rate_per_run_per_topic - error_rate_per_run_across_topics)
singo <- quatro %>%
filter(new_topic==3)
final <- singo %>%
rename(ourmodel = `model_.x`) %>%
rename(niels = diff) %>%
select(niels, ourmodel)
m1 <- ulam(
alist(
niels ~ dnorm(mu, sigma),
mu <- a[ourmodel],
a[ourmodel] ~ dnorm(0.40, 0.15) ,
sigma ~ dexp(2)
), data = final, chains = 4, cores = 4)
View(final)
# JONF: Merging topics with classification report and minimizing df
topic_classf_JONF <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_JONF <- topic_classf_JONF[complete.cases(topic_classf_JONF), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_JONF$model_ <- 1
# SCANDIBERT: Merging topics with classification report and minimizing df
topic_classf_SCANDIBERT <- merge(classf_report_vestin,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_SCANDIBERT <- topic_classf_SCANDIBERT[complete.cases(topic_classf_SCANDIBERT), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_SCANDIBERT$model_ <- 2
# AELECTRA: Merging topics with classification report and minimizing df
topic_classf_AELECTRA <- merge(classf_report_aelectra,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_AELECTRA <- topic_classf_AELECTRA[complete.cases(topic_classf_AELECTRA), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_AELECTRA$model_ <- 3
# XLM_BASE: Merging topics with classification report and minimizing df
topic_classf_XLM_BASE <- merge(classf_report_XLM_base,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_BASE <- topic_classf_XLM_BASE[complete.cases(topic_classf_XLM_BASE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_BASE$model_ <- 4
# XLM_LARGE: Merging topics with classification report and minimizing df
topic_classf_XLM_LARGE <- merge(classf_report_XLM_large,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_LARGE <- topic_classf_XLM_LARGE[complete.cases(topic_classf_XLM_LARGE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_LARGE$model_ <- 5
# combining
all_models <- rbind(topic_classf_XLM_LARGE, topic_classf_XLM_BASE, topic_classf_AELECTRA, topic_classf_SCANDIBERT, topic_classf_JONF)
error_rate_per_run_per_topic <- all_models %>%
group_by(new_topic, run, model_) %>%
summarise("error_rate_per_run_per_topic" = mean(MISS_binary))
error_rate_per_run_across_topics <- all_models %>%
group_by(run, model_) %>%
summarise("error_rate_per_run_across_topics" = mean(MISS_binary))
tress <- merge(error_rate_per_run_per_topic, error_rate_per_run_across_topics, by = "run", all.x = T, all.y = F)
quatro <- tress %>%
mutate(diff = error_rate_per_run_per_topic - error_rate_per_run_across_topics)
# uno <- topic_classf %>%
#   group_by(new_topic, run) %>%
#   summarise("error_rate_per_run_per_topic" = mean(MISS_binary))
#
# dos <- topic_classf %>%
#   group_by(run) %>%
#   summarise("error_rate_per_run_across_topics" = mean(MISS_binary))
#
# tress <- merge(uno, dos, by ="run", all.x = T, all.y = F)
#
# quatro <- tress %>%
#   mutate(diff = error_rate_per_run_per_topic - error_rate_per_run_across_topics)
singo <- quatro %>%
filter(new_topic==3)
final <- singo %>%
rename(ourmodel = `model_.x`) %>%
rename(niels = diff) %>%
select(niels, ourmodel)
m1 <- ulam(
alist(
niels ~ dnorm(mu, sigma),
mu <- a[ourmodel],
a[ourmodel] ~ dnorm(0.40, 0.15) ,
sigma ~ dexp(2)
), data = final, chains = 4, cores = 4)
precis(m1, depth =2)
plot(coeftab(m1),by.model=TRUE)
# JONF: Merging topics with classification report and minimizing df
topic_classf_JONF <- merge(classf_report_jonf,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_JONF <- topic_classf_JONF[complete.cases(topic_classf_JONF), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_JONF$model_ <- 4
# SCANDIBERT: Merging topics with classification report and minimizing df
topic_classf_SCANDIBERT <- merge(classf_report_vestin,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_SCANDIBERT <- topic_classf_SCANDIBERT[complete.cases(topic_classf_SCANDIBERT), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_SCANDIBERT$model_ <- 2
# AELECTRA: Merging topics with classification report and minimizing df
topic_classf_AELECTRA <- merge(classf_report_aelectra,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_AELECTRA <- topic_classf_AELECTRA[complete.cases(topic_classf_AELECTRA), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_AELECTRA$model_ <- 3
# XLM_BASE: Merging topics with classification report and minimizing df
topic_classf_XLM_BASE <- merge(classf_report_XLM_base,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_BASE <- topic_classf_XLM_BASE[complete.cases(topic_classf_XLM_BASE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_BASE$model_ <- 1
# XLM_LARGE: Merging topics with classification report and minimizing df
topic_classf_XLM_LARGE <- merge(classf_report_XLM_large,topics, by = "Text", all.x = T, all.y = F) %>%
rename(run = filename) %>%
select(Text, `Predicted Labels`, `True Labels`, new_topic, MISS_binary, run)
topic_classf_XLM_LARGE <- topic_classf_XLM_LARGE[complete.cases(topic_classf_XLM_LARGE), ] # removing rows with NA's in topic (50 rows of which 10 were in Arabic)
topic_classf_XLM_LARGE$model_ <- 5
# combining
all_models <- rbind(topic_classf_XLM_LARGE, topic_classf_XLM_BASE, topic_classf_AELECTRA, topic_classf_SCANDIBERT, topic_classf_JONF)
error_rate_per_run_per_topic <- all_models %>%
group_by(new_topic, run, model_) %>%
summarise("error_rate_per_run_per_topic" = mean(MISS_binary))
error_rate_per_run_across_topics <- all_models %>%
group_by(run, model_) %>%
summarise("error_rate_per_run_across_topics" = mean(MISS_binary))
tress <- merge(error_rate_per_run_per_topic, error_rate_per_run_across_topics, by = "run", all.x = T, all.y = F)
quatro <- tress %>%
mutate(diff = error_rate_per_run_per_topic - error_rate_per_run_across_topics)
# uno <- topic_classf %>%
#   group_by(new_topic, run) %>%
#   summarise("error_rate_per_run_per_topic" = mean(MISS_binary))
#
# dos <- topic_classf %>%
#   group_by(run) %>%
#   summarise("error_rate_per_run_across_topics" = mean(MISS_binary))
#
# tress <- merge(uno, dos, by ="run", all.x = T, all.y = F)
#
# quatro <- tress %>%
#   mutate(diff = error_rate_per_run_per_topic - error_rate_per_run_across_topics)
singo <- quatro %>%
filter(new_topic==3)
final <- singo %>%
rename(ourmodel = `model_.x`) %>%
rename(niels = diff) %>%
select(niels, ourmodel)
m1 <- ulam(
alist(
niels ~ dnorm(mu, sigma),
mu <- a[ourmodel],
a[ourmodel] ~ dnorm(0.40, 0.15) ,
sigma ~ dexp(2)
), data = final, chains = 4, cores = 4)
precis(m1, depth =2)
plot(coeftab(m1),by.model=TRUE)
m1 %>%
spread_draws(intercept[ourmodel]) %>%
compare_levels(intercept, by = ourmodel) %>%
ggplot(aes(y = ourmodel, x = intercept)) +
stat_halfeye()
m1 %>%
spread_draws(intercept[ourmodel]) %>%
#compare_levels(intercept, by = ourmodel) %>%
ggplot(aes(y = ourmodel, x = intercept)) +
stat_halfeye()
library(tidybayes)
pacman::p_load(tidybayes)
pacman::p_load(tidybayes)
m1 %>%
spread_draws(intercept[ourmodel]) %>%
compare_levels(intercept, by = ourmodel) %>%
ggplot(aes(y = ourmodel, x = intercept)) +
stat_halfeye()
m1 %>%
spread_draws(intercept[ourmodel])
pacman::p_load(tidybayes.rethinking)
pacman::p_load(tidybayes.rethinking)
install.packages("devtools")     # only necessary if you don't have devtools already
devtools::install_github("mjskay/tidybayes.rethinking")
pacman::p_load(tidybayes.rethinking)
m1 %>%
spread_draws(intercept[ourmodel]) %>%
compare_levels(intercept, by = ourmodel) %>%
ggplot(aes(y = ourmodel, x = intercept)) +
stat_halfeye()
m1 %>%
spread_draws(intercept[ourmodel])
m1 %>%
spread_draws(a[ourmodel])
precis(m1, depth =1)
precis(m1, depth =2)
m1 %>%
spread_draws(a[ourmodel])
