{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning models\n",
        "All notebooks for finetuning models were the same, only the model changed. This notebook shows how we fine-tuned ```flax-community/roberta-base-danish``` but could just as have been for any other model.\n",
        "\n",
        "The notebook requires GPU access, otherwise it will either be very slow or the script will crash. \n"
      ],
      "metadata": {
        "id": "4zzTfRrg5Vly"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKU3m0z9Vat9"
      },
      "source": [
        "# GPU, installing packages and login to WANDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGPPbq1bDyFe",
        "outputId": "b1041613-8497-4302-9c0a-802c17e8d8ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 28 10:16:17 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Initialize GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkq6fKgGViDR"
      },
      "source": [
        "## Installing required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPqH5u4AVf27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb196a3-5b6a-49f7-b461-f5809ab33d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 5.5 MB 4.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 45 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 89.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 62.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 84.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 52.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 73.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 793 kB 84.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 63.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 86.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 90.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 80.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 89.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 75.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 168 kB 88.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 96.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 96.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 97.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 97.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 92.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 87.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 97.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 93.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 90.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 92.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 89.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 94.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 79.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 998 kB 83.4 MB/s \n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipython~=7.9.0, but you have ipython 7.34.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers transformers-interpret datasets evaluate wandb tensorflow spacy spacy_langdetect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fpz2ux3nV86k"
      },
      "source": [
        "# Importing packages, data and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsAyvdU4V75M",
        "outputId": "05c9e1a0-6b1d-4550-89c1-f940ca09ca1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration ScandEval--angry-tweets-mini-0892d580b45b5ec4\n",
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/ScandEval___parquet/ScandEval--angry-tweets-mini-0892d580b45b5ec4/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
            "WARNING:datasets.builder:Using custom data configuration DDSC--twitter-sent-6877aa7c00ce8b34\n",
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/DDSC___parquet/DDSC--twitter-sent-6877aa7c00ce8b34/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
            "Some weights of the model checkpoint at flax-community/roberta-base-danish were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at flax-community/roberta-base-danish and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset, load_metric #load_dataset will cache the dataset to avoid downloading it again the next time you run this cell.\n",
        "import datasets as datasets\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
        "import pandas as pd\n",
        "\n",
        "# Loading data\n",
        "dataset_1 = datasets.load_dataset('ScandEval/angry-tweets-mini', split='train+test+val')# sentiment classification dataset: negative, neutral or positive\n",
        "\n",
        "# Loading larger dataset\n",
        "dataset_2 = load_dataset(\"DDSC/twitter-sent\", split='train+test')\n",
        "\n",
        "\n",
        "# Loading model and tokenizer\n",
        "model_name = \"flax-community/roberta-base-danish\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "num_labels=3\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels) # giving the number of labels and huggingface path,beware that \"AutoModelForSequenceClassification\" will automatically add an empty linear layer on top of the model, we don't need to do that manually"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "raw_dataset = concatenate_datasets([dataset_1, dataset_2])"
      ],
      "metadata": {
        "id": "RdhcNzoW1Lht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import dataset_dict, Dataset\n",
        "\n",
        "pandas = pd.DataFrame(raw_dataset)\n",
        "\n",
        "pandas.loc[pandas.label == 'negativ', 'label'] = \"negative\"\n",
        "pandas.loc[pandas.label == 'positiv', 'label'] = \"positive\""
      ],
      "metadata": {
        "id": "aaqSWY2u53-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing data"
      ],
      "metadata": {
        "id": "6j51pDg56O-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing duplicate rows**"
      ],
      "metadata": {
        "id": "m1Mx5XYo6rn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# removing duplicate rows\n",
        "pandas = pandas.drop_duplicates().reset_index()\n",
        "pandas = pandas.drop(['index'], axis = 1)"
      ],
      "metadata": {
        "id": "A4P7Jn10ww1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing specific words**"
      ],
      "metadata": {
        "id": "sD71BmjaA4Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_mystopwords(sentence, stopword_list):\n",
        "    tokens = sentence.split(\" \")\n",
        "    tokens_filtered= [word for word in tokens if not word in stopword_list]\n",
        "    return (\" \").join(tokens_filtered)\n",
        "\n",
        "# creating stopword list\n",
        "stopwords = [\"link\", \"rt\", \"amp\", \"@USER\", \"[LINK]\"]\n",
        "\n",
        "pandas.text = [remove_mystopwords(sentence, stopwords) for sentence in pandas.text]"
      ],
      "metadata": {
        "id": "8ZAdrsSgsOpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing non-Danish sentences**"
      ],
      "metadata": {
        "id": "k3U5Uly-6eH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_eng = 1\n",
        "no_below_4 = 1\n",
        "no_ttr_below_3 = 1\n",
        "\n",
        "if no_eng == 1:\n",
        "  import spacy\n",
        "  from spacy.language import Language\n",
        "  from spacy_langdetect import LanguageDetector\n",
        "  import numpy as np\n",
        "  import pandas as pd\n",
        "\n",
        "  def get_lang_detector(nlp, name):\n",
        "    return LanguageDetector()\n",
        "    \n",
        "  # loading the language model instance that will be used for language detection\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  Language.factory(\"language_detector\", func=get_lang_detector)\n",
        "  nlp.add_pipe('language_detector', last=True)\n",
        "\n",
        "  # applying the language detection to the data\n",
        "  data = [nlp(text_i)._.language for i, text_i in enumerate(pandas['text'])]\n",
        "\n",
        "  # transforming the data to a pandas dataframe\n",
        "  data_pd = pd.DataFrame.from_dict(data)\n",
        "  data_pd[\"tweets\"] = pandas['text'] # adding the tweets to the dataframe\n",
        "\n",
        "  # removing all that have been detected to be english\n",
        " # data_pd_1 = data_pd[data_pd['language'] != 'en']"
      ],
      "metadata": {
        "id": "RGJqIv6EufXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Removing sentences of length <4 words**"
      ],
      "metadata": {
        "id": "uMGIMN5S6ulN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_pd['label'] = pandas['label']\n",
        "\n",
        "if no_below_4 == 1:\n",
        "\n",
        "  # removing all with a sentence length below 4\n",
        "  data_pd['tweet_len'] = [len(data_pd['tweets'].iloc[i].split()) for i in range(data_pd.shape[0])]\n",
        "  data_pd = data_pd[data_pd['tweet_len'] > 3]\n",
        "\n",
        "data_pd_3 = data_pd[data_pd['language'] != 'en']\n",
        "\n",
        "data_pd_4 = data_pd_3.drop(['score', 'language', 'tweet_len'], axis= 1)\n",
        "data_pd_5 = data_pd_4.rename(columns = {'tweets': 'text'})"
      ],
      "metadata": {
        "id": "VVnGrzN3sWtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset = Dataset.from_dict(data_pd_5)\n",
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Z4XPMVsQQ7",
        "outputId": "c52b7584-d73a-4d2a-c4b9-a84426b5b413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 3806\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xovnnh_pWM93"
      },
      "source": [
        "**Changing predefined dataset splits**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwSDAMaOWEPa"
      },
      "outputs": [],
      "source": [
        "from datasets import concatenate_datasets, dataset_dict, Dataset\n",
        "\n",
        "#### combine datasets\n",
        "#dataset_combined = concatenate_datasets([raw_dataset['val'], raw_dataset['train'], raw_dataset['test']])\n",
        "\n",
        "##### 60% train, 40% test\n",
        "train_test = raw_dataset.train_test_split(test_size=0.4, seed = 42) # seed when splitting data is fairly crucial when comparing different models, to make sure they get the same test and training data.\n",
        "# 20% validation, 20% test\n",
        "test_valid = train_test['test'].train_test_split(test_size=0.5, seed = 42)\n",
        "# combining into test 60%, test 20%, val 20%\n",
        "dataset_recombined = datasets.DatasetDict({\n",
        "    'train': train_test['train'],\n",
        "    'valid': test_valid['train'],\n",
        "    'test': test_valid['test']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "f4d64efb679f4f6c9bc957bf1d2a00d4",
            "ec975ed4c28443c6a4c8c0c5496498cf",
            "a7322aff86f540dbb0066ad4f18ed8e6",
            "d12d1ea10c15419a813bf3c430d6dd28",
            "427c0def8d584fd987d290ebd2e7b650",
            "cbf16d5a7ec04015ba9c7bb1ebff0336",
            "8faf336977ed494ca3c1dcbaef109655",
            "0cb41813b3224fb2b5122c95e7a797f4",
            "5541bdc9c4d74ec5890158bb7d1db847",
            "fa344af4be974b60a11ea862920394d7",
            "d55c424af7004a0582428e1235087ecf",
            "6c6071ac70864869b6a988659dcae17b",
            "ba21747f291d40a09478442882f01972",
            "b4480a2a4974450fa442f81ba6102fbf",
            "6cd53cacb85540d49a77058b5d304fd9",
            "8d08aca007eb433081904c0204310ef9",
            "813e4e29fcb54113909afdb3f6300d1b",
            "5d45bc7e64004eb1b263c52c424c493d",
            "9a238f5445874706a620834688236081",
            "b8bed24945244a3b93a4b92eb85084ff",
            "2175fcb9cec043288ff8e18ce34ed0ae",
            "6b4d4da70f444d188bad19b180a54c44",
            "8120788d0f254f869d9d6b85e4cf2583",
            "d0162993232e4379ab6414aa3fa06ee3",
            "19246bcafaaf488db3992e295b253d2a",
            "5bb83b7b75a9419b98ed50e6665b5ab8",
            "eb34ed630f1d47ea88899760831ab869",
            "37748dc2a29d4385893c6152857e88bb",
            "506068e2c22f476da19d9f06cd8e92a1",
            "0c58c228205847f78202c33f220aceef",
            "224e7670a3c24c66957d1a8cb0cae2e0",
            "769bf522f4264cb7a2b573d991432491",
            "afabbfba35364718af1bd467fae32139"
          ]
        },
        "id": "uTn2lSJ0W1Lq",
        "outputId": "8f14ff2b-0341-4dd6-ed5b-d83c9a5d269a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4d64efb679f4f6c9bc957bf1d2a00d4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c6071ac70864869b6a988659dcae17b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8120788d0f254f869d9d6b85e4cf2583"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# creating a ClassLabel instance to use for mapping classes to integers (it is needed for creating tensors)\n",
        "from datasets import ClassLabel\n",
        "labels_cl = ClassLabel(num_classes=3, names=['negative', 'neutral', 'positive'])\n",
        "\n",
        "# defining a function to tokenize the text and translate all labels into integers intead of strings\n",
        "def tokenize_function(example):\n",
        "  tokens = tokenizer(example[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "  tokens['label'] = labels_cl.str2int(example['label'])\n",
        "  return tokens\n",
        "\n",
        "tokenized_datasets = dataset_recombined.map(tokenize_function, batched=True, remove_columns=dataset_recombined['train'].column_names) # batched=True speeds up tokenization by allowing to process multiple lines at once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evh5meCGXow0"
      },
      "source": [
        "## Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUkun4YuXN3_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    metric0 = evaluate.load(\"accuracy\")\n",
        "    metric1 = evaluate.load(\"precision\")\n",
        "    metric2 = evaluate.load(\"recall\")\n",
        "    metric3 = evaluate.load(\"f1\")\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    accuracy = metric0.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
        "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIcx0Y5qX_PB"
      },
      "source": [
        "## Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THSR8xopXxBc"
      },
      "outputs": [],
      "source": [
        "# Makes the model stop when validation loss hasn't improved for n(early_stopping_patience) epochs\n",
        "early_stop = EarlyStoppingCallback(early_stopping_patience = 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vycSmadXPjV"
      },
      "source": [
        " ## Defining hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7hR8RmbXgw-"
      },
      "outputs": [],
      "source": [
        "batch_size = 128 # stating batch size\n",
        "epochs = 200\n",
        "learning_rate = 2e-5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WANDB"
      ],
      "metadata": {
        "id": "ae-aATLyO7eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"bachelor_thesis_cogsci\",\n",
        "           tags=[\"HPsearch_nbailab\"])\n",
        "\n",
        "wandb.config.dropout = 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "sseOKi04OLC9",
        "outputId": "6a762985-a922-4e0a-86dc-20c4f6ad8044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjorgenhw\u001b[0m (\u001b[33mbachelor_thesis_cogsci\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_102347-1cxs0fe6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/bachelor_thesis_cogsci/runs/1cxs0fe6\" target=\"_blank\">dutiful-morning-148</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/bachelor_thesis_cogsci\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning"
      ],
      "metadata": {
        "id": "Ek2DVbL_iNyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q optuna ray[tune]"
      ],
      "metadata": {
        "id": "8_HzFMTwiRTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edaf69d4-4b3d-4633-fc56-75a776d531d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 348 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 59.1 MB 107.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 209 kB 92.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 147 kB 90.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 112 kB 63.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 71.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 84.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 468 kB 62.4 MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "    return model #model = AutoModelForSequenceClassification.from_pretrained(model, num_labels=3) (defined earlier)"
      ],
      "metadata": {
        "id": "P6hjgpg1jmRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training parameters**"
      ],
      "metadata": {
        "id": "ClAgLLiil4f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(output_dir=model_name, \n",
        "                                  evaluation_strategy = \"epoch\",\n",
        "                                  save_strategy = \"epoch\", \n",
        "                                  num_train_epochs = epochs, \n",
        "                                  per_device_train_batch_size = batch_size,\n",
        "                                  per_device_eval_batch_size = batch_size,\n",
        "                                  learning_rate = learning_rate,\n",
        "                                  weight_decay=0.01,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  report_to=\"wandb\",\n",
        "                                  save_total_limit = 2)"
      ],
      "metadata": {
        "id": "Gug2XryfkLCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model_init=model_init,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks = [early_stop]\n",
        ")"
      ],
      "metadata": {
        "id": "b8YQqLEkkF8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-6, 1e-4, log=True),\n",
        "        \"weight_decay\": trial.suggest_loguniform('weight_decay', 1e-4, 1e-2)\n",
        "    }"
      ],
      "metadata": {
        "id": "cBJKqZrAnS3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initializing hyperparameter tuning"
      ],
      "metadata": {
        "id": "gc6J_xui7fPj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "\n",
        "sampler = optuna.samplers.TPESampler()\n",
        "pruner = optuna.pruners.MedianPruner(n_warmup_steps=10)\n",
        "\n",
        "\n",
        "\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    n_trials=10, \n",
        "    direction=\"minimize\", \n",
        "    hp_space=my_hp_space, \n",
        "    backend = \"optuna\",\n",
        "    sampler = sampler,\n",
        "    pruner = pruner\n",
        "    )"
      ],
      "metadata": {
        "id": "o_TjV2GDmWx8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9fe0f7c9b7064037b1f54ee151a11c28",
            "0fdd594589934f568d42be4c5d3dbaa8",
            "8ad27001095b40a19f022ad90661098f",
            "b4d3260684714ad2b1981cc92366f882",
            "bf932a6922f14b8cab6101c207195d61",
            "5edb66fc85824b7684ea73d12cde8c41",
            "19a88357d59b479db9e1e039fd23ae02",
            "0028181811e04e5abb1e30d76139e320",
            "853764544e0d4420aaa141a9088553f9",
            "261ce02885d9479597d52de092c0ce90",
            "73540108250b4982bbeee9f82c755aa6",
            "962875cceb45480f94802be1e6964753",
            "e03797a995254624a7a0edc3a36361ae",
            "c52e16075ac64f17abb5e5903391ce62",
            "d81797e3876e47fcad5eb01741eb4a6a",
            "4f8479d2a6064a56816465eefbf411f2",
            "d84f336426474ea3bcc2f25f034e165e",
            "ca99171d241546528d85a9ccbdb565b9",
            "124067acc9f74ebb9e40207e45c9c4b2",
            "9ce1136b7005499eb5229853a7cd9991",
            "82273548e68c4e6e83869642525a4cbf",
            "c96f95363b7c477cb8d8fb97618de3b2",
            "dfad5157c4574b8597eda82ac5b629fb",
            "6b36478599f840dc9604e07d8df831b0",
            "97d6d4074cb544a597f022c234f90584",
            "0ac58ae8bd0d489a90142e0e593ef089",
            "b8b8bdd98df24d1db8f8d19055425811",
            "20a8f0cab3314210a3459fdd725d7d23",
            "97262b1264be4600934f1d1f7c16b12c",
            "7020c58d20754f9984ceae5506589e2e",
            "f91ade997acf49adafe9f412d3c185a0",
            "dabbd7a966534ad88e8b95c0d7be4514",
            "46a1903d35574062bcacb61acdd468c6",
            "1ad75ab7e3394b1f89571ebe9a8699c8",
            "e0917cf144fb4f64ba6dd9f02c4691ff",
            "1322e23024ce471db68239cbcd4f4f22",
            "e59de640b5d3442c8cdee0081578ae79",
            "8f087d619835449d9ee8d9ce6a7e1b73",
            "16923cb777024d8b81cb6dc49d1de632",
            "e0f6739084a64185a5243dac7c1651ac",
            "e5562c769c6a4180a776692a47e8699b",
            "8a2eb32309374a23aa121c4d0101b350",
            "98de1fc212d547d6a366b0ba6226d8b8",
            "18ab160427dc4d6e855316ff199fca4e",
            "e942179f22de4b75a77f7cc2306f9569",
            "5cad0b047d4b469e927a315bf516c397",
            "f2aabf5feb2e42478307ec7de2618f5f",
            "46dcac2dc82b415c83f6a9287537b063",
            "cd9a1d6a0cbd4f5ab5d483c9d7d36451",
            "dd894aed81a14478ab577238ea678dce",
            "9f33ab1a87114df7b99c8277eaf730d9",
            "78cc5fba74eb4326b8324f1be7e51dce",
            "2f71976fdfbb4e7f83b9a30561d5134e",
            "4054e2e7a7a940a981b5eafff3c0ab50",
            "045dd63f50e54a18b0e89c33c2375b8b",
            "f89792972e644c4b8619f73a727a1b16",
            "e51054406a094f67918b5527555ef0f9",
            "c19adb48150e4765a11721835f41c483",
            "1feb402b739e4120913dd85f82666bcc",
            "bd5894d462ad439d84178480559259c4",
            "f00d455158844c88b8903cd0c49a5146",
            "fc1fdba7f8234aa499ee91ef5a73fbeb",
            "6068e6c1bff245858ffa5362ec61767f",
            "cf7b154576094abdb4928482661fcd5c",
            "dd24d85d8f0b4b3d864fe7d3c522b0d2",
            "8b91cc1c7044483b9ca87cc286b581c2",
            "685420bc83cd45d7b5c2bd358fee60b1",
            "223cbc62f23641fb889b279e8be66406",
            "5405b644fbf84a1ebe1b9755ac2d1de8",
            "c9db43243b5d473780ce9b143375af54",
            "9f2d3f553e9a4447baa75d3f5b5d4480",
            "544a75140be84366afbe69465449f804",
            "db34d709d47e4b468ab92059d48e1eb8",
            "577269151bae497f90911eee99f438f4",
            "ba20317cda604df497d8675e7207218d",
            "5a5975553bef45099864bd905d902f17",
            "7589dafc0e334d40ae64016d2ae58020",
            "10903f19a84249459f87a7c8fe458f7f",
            "736fa318528a4d82822aa063ff80d4de",
            "72669b70d21a47a4bb9f80661b1c2ac4",
            "2f909cb1b6f64e68b48912df90394aee",
            "40cc824de5c54e119190df8e0e6e4eb8",
            "7e36cd971a314d909d1616aa68e0b971",
            "17bde09e8f744c2da8ebfc3c099ce18c",
            "c6184451e6954b22ba1fe6e9cce05c6e",
            "b4025501db924d929d31f6d66e90fccb",
            "574caf6116ff42738839bcc732b4df8e",
            "cfe30f200df74713869c9b0f52547c12",
            "d54df4c9cef841269338ebfb5e1eea19",
            "0fcf6dd35f9841849ccbeb9c6da74513",
            "5e54b202a4ae480482013c58b3eeb11b",
            "490ec2ba7bad49919020be066921c6e4",
            "5630d7b1e70c49f38d08069fe506e4cc",
            "2c4f2a1703844325badabd20d7c55fab",
            "0f6146b57dac4fdd9b19a11d2c922b46",
            "153d2dbb2c384c96b4eaca4a97f3375b",
            "c91ced643d384bd9b01fed1f796315d8",
            "2bc6c606397a420d9f739054f37086f5",
            "a4bc5f04e8d741208d773c072494a675",
            "854fea52a18d464587b59094c23b8da5",
            "43132dc684674ce89e416d23f31bf3b8",
            "3490d51978704deba7d72a1dab2e8963",
            "35023f9311304efd8a66164c2bc2fd49",
            "035033128a00458db2982bd7caf21ab0",
            "a02d7a22c1df42ffa51bb0a51996c3de",
            "4b0970aa19f14ddf910652af24959404",
            "b39a4d04c6364ddb8eba1f009619348d",
            "52421db347984b8881de97834d831e8e",
            "7ad5f8d75eb74a87b502298a311c9f94",
            "34462726cbe24d7c884ca323e69258c6",
            "824a70f0935a44acb932d30f189d5144",
            "a478337ed24d485786fa758c6d537244",
            "6d393091487e401eaef2c3430f339662",
            "1564484b205f490e9898c147104a0a84",
            "b35a2b4922f34adaabd85a37aeeccb71",
            "8c7024d0c72442fba4074fce03aa7dad"
          ]
        },
        "outputId": "b8320ff1-7934-4afa-8361-18a6e72e375f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-11-28 10:24:12,072]\u001b[0m A new study created in memory with name: no-name-17663d9a-56ae-44a0-abab-db7bc77e939c\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 1.0211178508623191e-06, 'weight_decay': 0.0035668865310456033}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fe0f7c9b7064037b1f54ee151a11c28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">dutiful-morning-148</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/bachelor_thesis_cogsci/runs/1cxs0fe6\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/bachelor_thesis_cogsci/runs/1cxs0fe6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_102347-1cxs0fe6/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_102419-3hvv7mwy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/3hvv7mwy\" target=\"_blank\">silver-mountain-668</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='972' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 972/3600 44:47 < 2:01:22, 0.36 it/s, Epoch 54/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.125018</td>\n",
              "      <td>0.347769</td>\n",
              "      <td>0.359674</td>\n",
              "      <td>0.347769</td>\n",
              "      <td>0.352620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.102760</td>\n",
              "      <td>0.421260</td>\n",
              "      <td>0.412319</td>\n",
              "      <td>0.421260</td>\n",
              "      <td>0.412080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.089727</td>\n",
              "      <td>0.425197</td>\n",
              "      <td>0.409788</td>\n",
              "      <td>0.425197</td>\n",
              "      <td>0.399620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.077516</td>\n",
              "      <td>0.427822</td>\n",
              "      <td>0.420304</td>\n",
              "      <td>0.427822</td>\n",
              "      <td>0.391176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.072517</td>\n",
              "      <td>0.433071</td>\n",
              "      <td>0.426764</td>\n",
              "      <td>0.433071</td>\n",
              "      <td>0.383327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.060710</td>\n",
              "      <td>0.446194</td>\n",
              "      <td>0.438701</td>\n",
              "      <td>0.446194</td>\n",
              "      <td>0.397581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.057013</td>\n",
              "      <td>0.446194</td>\n",
              "      <td>0.438887</td>\n",
              "      <td>0.446194</td>\n",
              "      <td>0.400846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.056450</td>\n",
              "      <td>0.429134</td>\n",
              "      <td>0.429545</td>\n",
              "      <td>0.429134</td>\n",
              "      <td>0.393532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.040166</td>\n",
              "      <td>0.459318</td>\n",
              "      <td>0.452581</td>\n",
              "      <td>0.459318</td>\n",
              "      <td>0.420635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.024630</td>\n",
              "      <td>0.475066</td>\n",
              "      <td>0.471017</td>\n",
              "      <td>0.475066</td>\n",
              "      <td>0.433427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.017023</td>\n",
              "      <td>0.486877</td>\n",
              "      <td>0.478380</td>\n",
              "      <td>0.486877</td>\n",
              "      <td>0.454486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.009986</td>\n",
              "      <td>0.494751</td>\n",
              "      <td>0.482382</td>\n",
              "      <td>0.494751</td>\n",
              "      <td>0.471194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.990079</td>\n",
              "      <td>0.514436</td>\n",
              "      <td>0.515961</td>\n",
              "      <td>0.514436</td>\n",
              "      <td>0.488173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.983495</td>\n",
              "      <td>0.526247</td>\n",
              "      <td>0.517185</td>\n",
              "      <td>0.526247</td>\n",
              "      <td>0.507163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.968328</td>\n",
              "      <td>0.527559</td>\n",
              "      <td>0.521468</td>\n",
              "      <td>0.527559</td>\n",
              "      <td>0.511916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.955367</td>\n",
              "      <td>0.541995</td>\n",
              "      <td>0.536007</td>\n",
              "      <td>0.541995</td>\n",
              "      <td>0.527504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.946091</td>\n",
              "      <td>0.540682</td>\n",
              "      <td>0.532765</td>\n",
              "      <td>0.540682</td>\n",
              "      <td>0.526818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.933742</td>\n",
              "      <td>0.549869</td>\n",
              "      <td>0.544944</td>\n",
              "      <td>0.549869</td>\n",
              "      <td>0.536148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.921483</td>\n",
              "      <td>0.559055</td>\n",
              "      <td>0.554630</td>\n",
              "      <td>0.559055</td>\n",
              "      <td>0.546446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.910658</td>\n",
              "      <td>0.559055</td>\n",
              "      <td>0.551838</td>\n",
              "      <td>0.559055</td>\n",
              "      <td>0.546709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.905093</td>\n",
              "      <td>0.559055</td>\n",
              "      <td>0.559566</td>\n",
              "      <td>0.559055</td>\n",
              "      <td>0.553395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.890176</td>\n",
              "      <td>0.577428</td>\n",
              "      <td>0.568708</td>\n",
              "      <td>0.577428</td>\n",
              "      <td>0.565924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.885363</td>\n",
              "      <td>0.582677</td>\n",
              "      <td>0.582619</td>\n",
              "      <td>0.582677</td>\n",
              "      <td>0.573608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.873789</td>\n",
              "      <td>0.591864</td>\n",
              "      <td>0.590304</td>\n",
              "      <td>0.591864</td>\n",
              "      <td>0.582643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.867718</td>\n",
              "      <td>0.597113</td>\n",
              "      <td>0.595734</td>\n",
              "      <td>0.597113</td>\n",
              "      <td>0.588714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.859989</td>\n",
              "      <td>0.599738</td>\n",
              "      <td>0.595249</td>\n",
              "      <td>0.599738</td>\n",
              "      <td>0.592128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.854802</td>\n",
              "      <td>0.603675</td>\n",
              "      <td>0.602548</td>\n",
              "      <td>0.603675</td>\n",
              "      <td>0.596586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.843542</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.600843</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.598651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.838204</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.605216</td>\n",
              "      <td>0.606299</td>\n",
              "      <td>0.598955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.828681</td>\n",
              "      <td>0.612861</td>\n",
              "      <td>0.610137</td>\n",
              "      <td>0.612861</td>\n",
              "      <td>0.607844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.829663</td>\n",
              "      <td>0.610236</td>\n",
              "      <td>0.607583</td>\n",
              "      <td>0.610236</td>\n",
              "      <td>0.603446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.821957</td>\n",
              "      <td>0.616798</td>\n",
              "      <td>0.613893</td>\n",
              "      <td>0.616798</td>\n",
              "      <td>0.610467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.817419</td>\n",
              "      <td>0.624672</td>\n",
              "      <td>0.622940</td>\n",
              "      <td>0.624672</td>\n",
              "      <td>0.620161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.812583</td>\n",
              "      <td>0.627297</td>\n",
              "      <td>0.625224</td>\n",
              "      <td>0.627297</td>\n",
              "      <td>0.622697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.811767</td>\n",
              "      <td>0.628609</td>\n",
              "      <td>0.625858</td>\n",
              "      <td>0.628609</td>\n",
              "      <td>0.623508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.808621</td>\n",
              "      <td>0.625984</td>\n",
              "      <td>0.622711</td>\n",
              "      <td>0.625984</td>\n",
              "      <td>0.620856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.807185</td>\n",
              "      <td>0.627297</td>\n",
              "      <td>0.624061</td>\n",
              "      <td>0.627297</td>\n",
              "      <td>0.623167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.814514</td>\n",
              "      <td>0.624672</td>\n",
              "      <td>0.623517</td>\n",
              "      <td>0.624672</td>\n",
              "      <td>0.620856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.809463</td>\n",
              "      <td>0.629921</td>\n",
              "      <td>0.628342</td>\n",
              "      <td>0.629921</td>\n",
              "      <td>0.626253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.806130</td>\n",
              "      <td>0.636483</td>\n",
              "      <td>0.633595</td>\n",
              "      <td>0.636483</td>\n",
              "      <td>0.632499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.806551</td>\n",
              "      <td>0.627297</td>\n",
              "      <td>0.625749</td>\n",
              "      <td>0.627297</td>\n",
              "      <td>0.623617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.805530</td>\n",
              "      <td>0.622047</td>\n",
              "      <td>0.620962</td>\n",
              "      <td>0.622047</td>\n",
              "      <td>0.618629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.810077</td>\n",
              "      <td>0.622047</td>\n",
              "      <td>0.621884</td>\n",
              "      <td>0.622047</td>\n",
              "      <td>0.618161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.802096</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.648166</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.648551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.804956</td>\n",
              "      <td>0.633858</td>\n",
              "      <td>0.633977</td>\n",
              "      <td>0.633858</td>\n",
              "      <td>0.632232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.800230</td>\n",
              "      <td>0.636483</td>\n",
              "      <td>0.636478</td>\n",
              "      <td>0.636483</td>\n",
              "      <td>0.635233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.806981</td>\n",
              "      <td>0.637795</td>\n",
              "      <td>0.637691</td>\n",
              "      <td>0.637795</td>\n",
              "      <td>0.635819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.803158</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.648634</td>\n",
              "      <td>0.650919</td>\n",
              "      <td>0.649088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.810272</td>\n",
              "      <td>0.639108</td>\n",
              "      <td>0.638026</td>\n",
              "      <td>0.639108</td>\n",
              "      <td>0.636466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.807611</td>\n",
              "      <td>0.640420</td>\n",
              "      <td>0.641978</td>\n",
              "      <td>0.640420</td>\n",
              "      <td>0.638419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.803724</td>\n",
              "      <td>0.645669</td>\n",
              "      <td>0.646204</td>\n",
              "      <td>0.645669</td>\n",
              "      <td>0.643964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.810952</td>\n",
              "      <td>0.664042</td>\n",
              "      <td>0.660403</td>\n",
              "      <td>0.664042</td>\n",
              "      <td>0.661351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.810545</td>\n",
              "      <td>0.643045</td>\n",
              "      <td>0.644442</td>\n",
              "      <td>0.643045</td>\n",
              "      <td>0.641622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.961700</td>\n",
              "      <td>0.810863</td>\n",
              "      <td>0.649606</td>\n",
              "      <td>0.649181</td>\n",
              "      <td>0.649606</td>\n",
              "      <td>0.647536</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "853764544e0d4420aaa141a9088553f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.55k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ce1136b7005499eb5229853a7cd9991"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f91ade997acf49adafe9f412d3c185a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a2eb32309374a23aa121c4d0101b350"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-18] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-180\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-180/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-180/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-180/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-180/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-144] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-198\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-198/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-198/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-198/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-198/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-216\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-216/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-216/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-216/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-216/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-180] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-234\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-234/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-234/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-234/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-234/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-198] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-252\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-252/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-252/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-252/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-252/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-216] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-270\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-270/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-270/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-270/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-270/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-234] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-288\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-288/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-288/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-288/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-288/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-252] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-306\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-306/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-306/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-306/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-306/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-270] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-324\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-324/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-324/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-324/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-324/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-288] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-342\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-342/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-342/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-342/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-342/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-306] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-360\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-360/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-360/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-360/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-360/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-324] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-378\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-378/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-378/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-378/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-378/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-342] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-396\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-396/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-396/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-396/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-396/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-360] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-414\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-414/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-414/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-414/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-414/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-378] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-432\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-432/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-432/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-432/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-432/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-396] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-450\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-450/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-450/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-450/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-450/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-414] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-468\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-468/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-468/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-468/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-468/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-432] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-486\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-486/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-486/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-486/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-486/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-450] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-504\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-504/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-504/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-504/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-504/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-468] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-522\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-522/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-522/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-522/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-522/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-486] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-540\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-540/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-540/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-540/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-540/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-504] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-558\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-558/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-558/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-558/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-558/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-522] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-576\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-576/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-576/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-576/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-576/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-540] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-594\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-594/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-594/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-594/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-594/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-558] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-612\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-612/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-612/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-612/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-612/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-576] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-630\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-630/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-630/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-630/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-630/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-594] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-648\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-648/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-648/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-648/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-648/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-612] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-666\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-666/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-666/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-666/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-666/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-630] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-684\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-684/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-684/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-684/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-684/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-648] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-702\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-702/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-702/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-702/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-702/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-684] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-720\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-720/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-720/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-720/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-720/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-666] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-738\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-738/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-738/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-738/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-738/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-702] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-756\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-756/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-756/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-756/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-756/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-720] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-774\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-774/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-774/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-774/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-774/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-738] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-792\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-792/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-792/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-792/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-792/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-756] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-810\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-810/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-810/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-810/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-810/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-774] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-828\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-828/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-828/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-828/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-828/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-792] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-846\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-846/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-846/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-846/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-846/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-810] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-864\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-864/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-864/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-864/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-864/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-846] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-882\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-882/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-882/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-882/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-882/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-864] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-900\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-900/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-900/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-900/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-900/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-882] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-918\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-918/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-918/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-918/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-918/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-900] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-936\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-936/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-936/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-936/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-936/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-918] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-954\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-954/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-954/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-954/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-954/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-936] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-0/checkpoint-972\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-0/checkpoint-972/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-0/checkpoint-972/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-0/checkpoint-972/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-0/checkpoint-972/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-0/checkpoint-954] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/run-0/checkpoint-828 (score: 0.800229549407959).\n",
            "\u001b[32m[I 2022-11-28 11:09:18,096]\u001b[0m Trial 0 finished with value: 2.595929793216958 and parameters: {'learning_rate': 1.0211178508623191e-06, 'weight_decay': 0.0035668865310456033}. Best is trial 0 with value: 2.595929793216958.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 7.097988675284114e-05, 'weight_decay': 0.008678372413196803}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.760 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.000969…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f71976fdfbb4e7f83b9a30561d5134e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███</td></tr><tr><td>eval/f1</td><td>▁▂▂▂▂▂▃▃▃▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███</td></tr><tr><td>eval/loss</td><td>██▇▇▇▇▆▆▆▅▅▅▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▂▂▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███</td></tr><tr><td>eval/recall</td><td>▁▃▃▃▃▃▃▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇█▇███</td></tr><tr><td>eval/runtime</td><td>█▁▁▁▁▄▁▂▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▂▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>▁████▅█▇████████▇▇██████▇████▇███▇█▇█▇▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁████▅█▇████████▇▇██████▇████▇███▇█▇█▇▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.64961</td></tr><tr><td>eval/f1</td><td>0.64754</td></tr><tr><td>eval/loss</td><td>0.81086</td></tr><tr><td>eval/precision</td><td>0.64918</td></tr><tr><td>eval/recall</td><td>0.64961</td></tr><tr><td>eval/runtime</td><td>5.0718</td></tr><tr><td>eval/samples_per_second</td><td>150.241</td></tr><tr><td>eval/steps_per_second</td><td>1.183</td></tr><tr><td>train/epoch</td><td>54.0</td></tr><tr><td>train/global_step</td><td>972</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.9617</td></tr><tr><td>train/total_flos</td><td>2.8722687631041024e+16</td></tr><tr><td>train/train_loss</td><td>0.78236</td></tr><tr><td>train/train_runtime</td><td>2705.9728</td></tr><tr><td>train/train_samples_per_second</td><td>168.738</td></tr><tr><td>train/train_steps_per_second</td><td>1.33</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">silver-mountain-668</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/3hvv7mwy\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/3hvv7mwy</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_102419-3hvv7mwy/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_110922-2jue9fpz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/2jue9fpz\" target=\"_blank\">genial-snow-669</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 180/3600 08:16 < 2:39:05, 0.36 it/s, Epoch 10/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.868492</td>\n",
              "      <td>0.637795</td>\n",
              "      <td>0.638915</td>\n",
              "      <td>0.637795</td>\n",
              "      <td>0.635773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.800372</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.695098</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.673525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.863975</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.684785</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.672514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.961372</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.677061</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.674446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.312872</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.687958</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.676708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.404050</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.673280</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.670695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.405536</td>\n",
              "      <td>0.637795</td>\n",
              "      <td>0.697995</td>\n",
              "      <td>0.637795</td>\n",
              "      <td>0.635482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.405780</td>\n",
              "      <td>0.699475</td>\n",
              "      <td>0.700066</td>\n",
              "      <td>0.699475</td>\n",
              "      <td>0.697834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.462885</td>\n",
              "      <td>0.691601</td>\n",
              "      <td>0.689826</td>\n",
              "      <td>0.691601</td>\n",
              "      <td>0.686718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.442180</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.668244</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.668887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-18] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-144] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-1/checkpoint-180\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-1/checkpoint-180/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-1/checkpoint-180/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-1/checkpoint-180/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-1/checkpoint-180/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-1/checkpoint-162] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/run-1/checkpoint-36 (score: 0.8003721237182617).\n",
            "\u001b[32m[I 2022-11-28 11:17:46,595]\u001b[0m Trial 1 finished with value: 2.6783376348432544 and parameters: {'learning_rate': 7.097988675284114e-05, 'weight_decay': 0.008678372413196803}. Best is trial 0 with value: 2.595929793216958.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 2.2273657472732825e-06, 'weight_decay': 0.0028479556561878277}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f00d455158844c88b8903cd0c49a5146"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▆▅▅▅▁█▇▅</td></tr><tr><td>eval/f1</td><td>▁▅▅▅▆▅▁█▇▅</td></tr><tr><td>eval/loss</td><td>▂▁▂▃▆▇▇▇██</td></tr><tr><td>eval/precision</td><td>▁▇▆▅▇▅██▇▄</td></tr><tr><td>eval/recall</td><td>▁▅▆▅▅▅▁█▇▅</td></tr><tr><td>eval/runtime</td><td>▇▄█▃▇▁█▁▆▂</td></tr><tr><td>eval/samples_per_second</td><td>▂▅▁▆▂█▁█▃▇</td></tr><tr><td>eval/steps_per_second</td><td>▂▅▁▆▂█▁▇▃▇</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▄▅▆▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▄▅▆▆▇██</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.6706</td></tr><tr><td>eval/f1</td><td>0.66889</td></tr><tr><td>eval/loss</td><td>1.44218</td></tr><tr><td>eval/precision</td><td>0.66824</td></tr><tr><td>eval/recall</td><td>0.6706</td></tr><tr><td>eval/runtime</td><td>5.0652</td></tr><tr><td>eval/samples_per_second</td><td>150.439</td></tr><tr><td>eval/steps_per_second</td><td>1.185</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>180</td></tr><tr><td>train/total_flos</td><td>5319016227970560.0</td></tr><tr><td>train/train_loss</td><td>0.29384</td></tr><tr><td>train/train_runtime</td><td>508.1377</td></tr><tr><td>train/train_samples_per_second</td><td>898.575</td></tr><tr><td>train/train_steps_per_second</td><td>7.085</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">genial-snow-669</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/2jue9fpz\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/2jue9fpz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_110922-2jue9fpz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_111751-28yjvxv3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/28yjvxv3\" target=\"_blank\">wandering-glade-670</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:25 < 2:39:39, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.807220</td>\n",
              "      <td>0.700787</td>\n",
              "      <td>0.699850</td>\n",
              "      <td>0.700787</td>\n",
              "      <td>0.699231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.857132</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.693428</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.681615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.858071</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.690340</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.685780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.865185</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.687618</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.682449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.877061</td>\n",
              "      <td>0.683727</td>\n",
              "      <td>0.689400</td>\n",
              "      <td>0.683727</td>\n",
              "      <td>0.684939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.890857</td>\n",
              "      <td>0.696850</td>\n",
              "      <td>0.699576</td>\n",
              "      <td>0.696850</td>\n",
              "      <td>0.697070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.920534</td>\n",
              "      <td>0.683727</td>\n",
              "      <td>0.686316</td>\n",
              "      <td>0.683727</td>\n",
              "      <td>0.684666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.931244</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.686780</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.681020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.957150</td>\n",
              "      <td>0.696850</td>\n",
              "      <td>0.697568</td>\n",
              "      <td>0.696850</td>\n",
              "      <td>0.696596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-2/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-2/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-2/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-2/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-2/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-2/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-2/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-2/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-2/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-2/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-2/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-2/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/run-2/checkpoint-18 (score: 0.8072195649147034).\n",
            "\u001b[32m[I 2022-11-28 11:25:23,946]\u001b[0m Trial 2 finished with value: 2.7878647182463068 and parameters: {'learning_rate': 2.2273657472732825e-06, 'weight_decay': 0.0028479556561878277}. Best is trial 0 with value: 2.595929793216958.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 1.028708863162189e-06, 'weight_decay': 0.0002508550010714184}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▁▃▁▂▇▂▁▇</td></tr><tr><td>eval/f1</td><td>█▁▃▂▃▇▂▁▇</td></tr><tr><td>eval/loss</td><td>▁▃▃▄▄▅▆▇█</td></tr><tr><td>eval/precision</td><td>█▅▃▂▃█▁▁▇</td></tr><tr><td>eval/recall</td><td>█▁▃▁▂▇▂▁▇</td></tr><tr><td>eval/runtime</td><td>▅▅▅▃▃█▂▁▅</td></tr><tr><td>eval/samples_per_second</td><td>▄▄▄▆▆▁▇█▄</td></tr><tr><td>eval/steps_per_second</td><td>▄▄▅▆▆▁▇█▄</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.69685</td></tr><tr><td>eval/f1</td><td>0.6966</td></tr><tr><td>eval/loss</td><td>0.95715</td></tr><tr><td>eval/precision</td><td>0.69757</td></tr><tr><td>eval/recall</td><td>0.69685</td></tr><tr><td>eval/runtime</td><td>5.0964</td></tr><tr><td>eval/samples_per_second</td><td>149.517</td></tr><tr><td>eval/steps_per_second</td><td>1.177</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>162</td></tr><tr><td>train/total_flos</td><td>4787114605173504.0</td></tr><tr><td>train/train_loss</td><td>0.32121</td></tr><tr><td>train/train_runtime</td><td>457.2982</td></tr><tr><td>train/train_samples_per_second</td><td>998.473</td></tr><tr><td>train/train_steps_per_second</td><td>7.872</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">wandering-glade-670</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/28yjvxv3\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/28yjvxv3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_111751-28yjvxv3/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_112526-ccms9xe7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/ccms9xe7\" target=\"_blank\">skilled-thunder-671</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:26 < 2:39:52, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.823002</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.691427</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.688998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.840580</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.692376</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.686315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.845481</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.693955</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.687448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.848472</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.693991</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.687581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.855913</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.691920</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.687366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.863987</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.689315</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.683891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.867894</td>\n",
              "      <td>0.691601</td>\n",
              "      <td>0.695479</td>\n",
              "      <td>0.691601</td>\n",
              "      <td>0.691967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.880469</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.690256</td>\n",
              "      <td>0.686352</td>\n",
              "      <td>0.687336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.888521</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.689093</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.686018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-3/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-3/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-3/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-3/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-3/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-3/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-3/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-3/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-3/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-3/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-3/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-3/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/run-3/checkpoint-18 (score: 0.8230017423629761).\n",
            "\u001b[32m[I 2022-11-28 11:33:00,548]\u001b[0m Trial 3 finished with value: 2.7451893259858418 and parameters: {'learning_rate': 1.028708863162189e-06, 'weight_decay': 0.0002508550010714184}. Best is trial 0 with value: 2.595929793216958.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 1.8107146448855739e-06, 'weight_decay': 0.005707691859628772}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5405b644fbf84a1ebe1b9755ac2d1de8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▆▃▄▄▄▁█▄▃</td></tr><tr><td>eval/f1</td><td>▅▃▄▄▄▁█▄▃</td></tr><tr><td>eval/loss</td><td>▁▃▃▄▅▅▆▇█</td></tr><tr><td>eval/precision</td><td>▄▅▆▆▄▁█▂▁</td></tr><tr><td>eval/recall</td><td>▆▃▄▄▄▁█▄▃</td></tr><tr><td>eval/runtime</td><td>▄▆▆█▃▆▃▁▄</td></tr><tr><td>eval/samples_per_second</td><td>▅▃▃▁▆▃▆█▅</td></tr><tr><td>eval/steps_per_second</td><td>▅▃▃▁▆▃▆█▅</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68504</td></tr><tr><td>eval/f1</td><td>0.68602</td></tr><tr><td>eval/loss</td><td>0.88852</td></tr><tr><td>eval/precision</td><td>0.68909</td></tr><tr><td>eval/recall</td><td>0.68504</td></tr><tr><td>eval/runtime</td><td>5.0892</td></tr><tr><td>eval/samples_per_second</td><td>149.729</td></tr><tr><td>eval/steps_per_second</td><td>1.179</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>162</td></tr><tr><td>train/total_flos</td><td>4787114605173504.0</td></tr><tr><td>train/train_loss</td><td>0.34368</td></tr><tr><td>train/train_runtime</td><td>456.5483</td></tr><tr><td>train/train_samples_per_second</td><td>1000.113</td></tr><tr><td>train/train_steps_per_second</td><td>7.885</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">skilled-thunder-671</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/ccms9xe7\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/ccms9xe7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_112526-ccms9xe7/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_113305-2s00ou0b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/2s00ou0b\" target=\"_blank\">copper-capybara-672</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:25 < 2:39:29, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.848346</td>\n",
              "      <td>0.696850</td>\n",
              "      <td>0.698350</td>\n",
              "      <td>0.696850</td>\n",
              "      <td>0.696519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.885878</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.689821</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.677877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.880229</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.694486</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.689606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.889938</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.689698</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.683998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.897045</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.689860</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.686063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.909977</td>\n",
              "      <td>0.691601</td>\n",
              "      <td>0.694828</td>\n",
              "      <td>0.691601</td>\n",
              "      <td>0.692132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.930803</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.691699</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.689733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.942103</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.684021</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.679686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.963396</td>\n",
              "      <td>0.698163</td>\n",
              "      <td>0.700051</td>\n",
              "      <td>0.698163</td>\n",
              "      <td>0.698286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-4/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-4/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-4/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-4/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-4/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-4/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-4/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-4/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-4/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-4/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-4/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-4/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/run-4/checkpoint-18 (score: 0.8483456373214722).\n",
            "\u001b[32m[I 2022-11-28 11:40:37,556]\u001b[0m Trial 4 finished with value: 2.7946624415687777 and parameters: {'learning_rate': 1.8107146448855739e-06, 'weight_decay': 0.005707691859628772}. Best is trial 0 with value: 2.595929793216958.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 1.1710358144076615e-06, 'weight_decay': 0.0024880576744958052}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7589dafc0e334d40ae64016d2ae58020"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>█▁▅▃▄▆▅▂█</td></tr><tr><td>eval/f1</td><td>▇▁▅▃▄▆▅▂█</td></tr><tr><td>eval/loss</td><td>▁▃▃▄▄▅▆▇█</td></tr><tr><td>eval/precision</td><td>▇▄▆▃▄▆▄▁█</td></tr><tr><td>eval/recall</td><td>█▁▅▃▄▆▅▂█</td></tr><tr><td>eval/runtime</td><td>▃▃▅▁▆▄▂█▅</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▄█▃▅▇▁▄</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▃█▃▅▇▁▄</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.69816</td></tr><tr><td>eval/f1</td><td>0.69829</td></tr><tr><td>eval/loss</td><td>0.9634</td></tr><tr><td>eval/precision</td><td>0.70005</td></tr><tr><td>eval/recall</td><td>0.69816</td></tr><tr><td>eval/runtime</td><td>5.113</td></tr><tr><td>eval/samples_per_second</td><td>149.033</td></tr><tr><td>eval/steps_per_second</td><td>1.173</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>162</td></tr><tr><td>train/total_flos</td><td>4787114605173504.0</td></tr><tr><td>train/train_loss</td><td>0.29691</td></tr><tr><td>train/train_runtime</td><td>456.9479</td></tr><tr><td>train/train_samples_per_second</td><td>999.239</td></tr><tr><td>train/train_steps_per_second</td><td>7.878</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">copper-capybara-672</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/2s00ou0b\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/2s00ou0b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_113305-2s00ou0b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_114043-47d7r1fx</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/47d7r1fx\" target=\"_blank\">winter-sun-673</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  18/3600 00:37 < 2:20:27, 0.43 it/s, Epoch 1/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.871669</td>\n",
              "      <td>0.695538</td>\n",
              "      <td>0.696479</td>\n",
              "      <td>0.695538</td>\n",
              "      <td>0.695322</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "\u001b[32m[I 2022-11-28 11:41:28,023]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 1.6358357089468507e-05, 'weight_decay': 0.00027882917298134975}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.887 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.000831…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6184451e6954b22ba1fe6e9cce05c6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.69554</td></tr><tr><td>eval/f1</td><td>0.69532</td></tr><tr><td>eval/loss</td><td>0.87167</td></tr><tr><td>eval/precision</td><td>0.69648</td></tr><tr><td>eval/recall</td><td>0.69554</td></tr><tr><td>eval/runtime</td><td>5.0657</td></tr><tr><td>eval/samples_per_second</td><td>150.424</td></tr><tr><td>eval/steps_per_second</td><td>1.184</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>18</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">winter-sun-673</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/47d7r1fx\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/47d7r1fx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_114043-47d7r1fx/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_114132-3pe9g2kj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/3pe9g2kj\" target=\"_blank\">stoic-tree-674</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:25 < 2:39:31, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.941349</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.681839</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.681259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.071323</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.679285</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.675749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.149028</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.688823</td>\n",
              "      <td>0.688976</td>\n",
              "      <td>0.688799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.215278</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.686440</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.679600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.268815</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.687835</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.677114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.394922</td>\n",
              "      <td>0.687664</td>\n",
              "      <td>0.689565</td>\n",
              "      <td>0.687664</td>\n",
              "      <td>0.688384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.629775</td>\n",
              "      <td>0.657480</td>\n",
              "      <td>0.664344</td>\n",
              "      <td>0.657480</td>\n",
              "      <td>0.654840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.590895</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.691583</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.684930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.552670</td>\n",
              "      <td>0.690289</td>\n",
              "      <td>0.695629</td>\n",
              "      <td>0.690289</td>\n",
              "      <td>0.691705</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-6/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-6/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-6/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-6/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-6/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-6/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-6/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-6/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-6/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-6/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-6/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-6/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/run-6/checkpoint-18 (score: 0.94134920835495).\n",
            "\u001b[32m[I 2022-11-28 11:49:05,008]\u001b[0m Trial 6 finished with value: 2.7679114481576073 and parameters: {'learning_rate': 1.6358357089468507e-05, 'weight_decay': 0.00027882917298134975}. Best is trial 0 with value: 2.595929793216958.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 4.260295380119423e-06, 'weight_decay': 0.008445656800454237}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5630d7b1e70c49f38d08069fe506e4cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▆▆█▅▅▇▁▆█</td></tr><tr><td>eval/f1</td><td>▆▅▇▆▅▇▁▇█</td></tr><tr><td>eval/loss</td><td>▁▂▃▄▄▆██▇</td></tr><tr><td>eval/precision</td><td>▅▄▆▆▆▇▁▇█</td></tr><tr><td>eval/recall</td><td>▆▆█▅▅▇▁▆█</td></tr><tr><td>eval/runtime</td><td>▄█▂▁▃▂▃▃▅</td></tr><tr><td>eval/samples_per_second</td><td>▅▁▇█▆▇▆▆▄</td></tr><tr><td>eval/steps_per_second</td><td>▅▁▇█▆▇▆▅▄</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.69029</td></tr><tr><td>eval/f1</td><td>0.69171</td></tr><tr><td>eval/loss</td><td>1.55267</td></tr><tr><td>eval/precision</td><td>0.69563</td></tr><tr><td>eval/recall</td><td>0.69029</td></tr><tr><td>eval/runtime</td><td>5.1119</td></tr><tr><td>eval/samples_per_second</td><td>149.065</td></tr><tr><td>eval/steps_per_second</td><td>1.174</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>162</td></tr><tr><td>train/total_flos</td><td>5319016227970560.0</td></tr><tr><td>train/train_loss</td><td>0.12311</td></tr><tr><td>train/train_runtime</td><td>456.9322</td></tr><tr><td>train/train_samples_per_second</td><td>999.273</td></tr><tr><td>train/train_steps_per_second</td><td>7.879</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">stoic-tree-674</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/3pe9g2kj\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/3pe9g2kj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_114132-3pe9g2kj/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_114909-1492fxam</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/1492fxam\" target=\"_blank\">worthy-frog-675</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  18/3600 00:37 < 2:19:23, 0.43 it/s, Epoch 1/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.006448</td>\n",
              "      <td>0.695538</td>\n",
              "      <td>0.692730</td>\n",
              "      <td>0.695538</td>\n",
              "      <td>0.693469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "\u001b[32m[I 2022-11-28 11:49:50,906]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 8.924919766561136e-05, 'weight_decay': 0.00022652421826064277}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.040237…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "43132dc684674ce89e416d23f31bf3b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁</td></tr><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/precision</td><td>▁</td></tr><tr><td>eval/recall</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁</td></tr><tr><td>train/global_step</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.69554</td></tr><tr><td>eval/f1</td><td>0.69347</td></tr><tr><td>eval/loss</td><td>1.00645</td></tr><tr><td>eval/precision</td><td>0.69273</td></tr><tr><td>eval/recall</td><td>0.69554</td></tr><tr><td>eval/runtime</td><td>5.1163</td></tr><tr><td>eval/samples_per_second</td><td>148.935</td></tr><tr><td>eval/steps_per_second</td><td>1.173</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>18</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">worthy-frog-675</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/1492fxam\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/1492fxam</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_114909-1492fxam/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_114954-m51p0y40</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/m51p0y40\" target=\"_blank\">vague-paper-676</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:29 < 2:40:53, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.920397</td>\n",
              "      <td>0.653543</td>\n",
              "      <td>0.675565</td>\n",
              "      <td>0.653543</td>\n",
              "      <td>0.655510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.951824</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.674020</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.660286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.123179</td>\n",
              "      <td>0.654856</td>\n",
              "      <td>0.655878</td>\n",
              "      <td>0.654856</td>\n",
              "      <td>0.650570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.306013</td>\n",
              "      <td>0.662730</td>\n",
              "      <td>0.659891</td>\n",
              "      <td>0.662730</td>\n",
              "      <td>0.658307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.308832</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.685823</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.664943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.253387</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.675781</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.664048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.662563</td>\n",
              "      <td>0.648294</td>\n",
              "      <td>0.690669</td>\n",
              "      <td>0.648294</td>\n",
              "      <td>0.649038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.622404</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.672968</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.673560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.201128</td>\n",
              "      <td>0.658793</td>\n",
              "      <td>0.666766</td>\n",
              "      <td>0.658793</td>\n",
              "      <td>0.643362</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-8/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-8/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-8/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-8/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-8/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-8/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-8/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-8/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-8/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-8/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-8/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-8/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/run-8/checkpoint-18 (score: 0.920397162437439).\n",
            "\u001b[32m[I 2022-11-28 11:57:30,523]\u001b[0m Trial 8 finished with value: 2.6277135058644605 and parameters: {'learning_rate': 8.924919766561136e-05, 'weight_decay': 0.00022652421826064277}. Best is trial 0 with value: 2.595929793216958.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "Trial: {'learning_rate': 7.39655836590707e-05, 'weight_decay': 0.00027362712377112966}\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ad5f8d75eb74a87b502298a311c9f94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▂▆▃▅▆▆▁█▄</td></tr><tr><td>eval/f1</td><td>▄▅▃▄▆▆▂█▁</td></tr><tr><td>eval/loss</td><td>▁▁▂▃▃▃▅▅█</td></tr><tr><td>eval/precision</td><td>▅▅▁▂▇▅█▄▃</td></tr><tr><td>eval/recall</td><td>▂▆▃▅▆▆▁█▄</td></tr><tr><td>eval/runtime</td><td>▅▄▁▁█▃▅▇▁</td></tr><tr><td>eval/samples_per_second</td><td>▄▅██▁▆▄▂█</td></tr><tr><td>eval/steps_per_second</td><td>▄▅██▁▆▄▂▇</td></tr><tr><td>train/epoch</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.65879</td></tr><tr><td>eval/f1</td><td>0.64336</td></tr><tr><td>eval/loss</td><td>2.20113</td></tr><tr><td>eval/precision</td><td>0.66677</td></tr><tr><td>eval/recall</td><td>0.65879</td></tr><tr><td>eval/runtime</td><td>5.0494</td></tr><tr><td>eval/samples_per_second</td><td>150.908</td></tr><tr><td>eval/steps_per_second</td><td>1.188</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>162</td></tr><tr><td>train/total_flos</td><td>5319016227970560.0</td></tr><tr><td>train/train_loss</td><td>0.16628</td></tr><tr><td>train/train_runtime</td><td>459.5677</td></tr><tr><td>train/train_samples_per_second</td><td>993.542</td></tr><tr><td>train/train_steps_per_second</td><td>7.833</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">vague-paper-676</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/m51p0y40\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/m51p0y40</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_114954-m51p0y40/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20221128_115735-43d8d8nj</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/43d8d8nj\" target=\"_blank\">fast-fog-677</a></strong> to <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 180/3600 08:04 < 2:35:16, 0.37 it/s, Epoch 10/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.210971</td>\n",
              "      <td>0.653543</td>\n",
              "      <td>0.663371</td>\n",
              "      <td>0.653543</td>\n",
              "      <td>0.654579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.044037</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.695460</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.683973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.123331</td>\n",
              "      <td>0.698163</td>\n",
              "      <td>0.701714</td>\n",
              "      <td>0.698163</td>\n",
              "      <td>0.698936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.363359</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.686160</td>\n",
              "      <td>0.685039</td>\n",
              "      <td>0.676897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.325615</td>\n",
              "      <td>0.641732</td>\n",
              "      <td>0.676949</td>\n",
              "      <td>0.641732</td>\n",
              "      <td>0.644387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.509836</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.679322</td>\n",
              "      <td>0.681102</td>\n",
              "      <td>0.678639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.484062</td>\n",
              "      <td>0.690289</td>\n",
              "      <td>0.694544</td>\n",
              "      <td>0.690289</td>\n",
              "      <td>0.682628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.476684</td>\n",
              "      <td>0.687664</td>\n",
              "      <td>0.686338</td>\n",
              "      <td>0.687664</td>\n",
              "      <td>0.686116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.563144</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.675941</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.671290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.726755</td>\n",
              "      <td>0.620735</td>\n",
              "      <td>0.654785</td>\n",
              "      <td>0.620735</td>\n",
              "      <td>0.623568</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-18/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-18/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-18/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-36/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-36/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-36/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-54/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-54/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-54/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-9/checkpoint-18] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-72/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-72/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-72/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-9/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-90/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-90/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-90/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-9/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-108/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-108/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-108/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-9/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-126/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-126/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-126/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-9/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-144/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-144/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-144/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-9/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/run-9/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/run-9/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/run-9/checkpoint-162/pytorch_model.bin\n",
            "tokenizer config file saved in NbAiLab/nb-bert-large/run-9/checkpoint-162/tokenizer_config.json\n",
            "Special tokens file saved in NbAiLab/nb-bert-large/run-9/checkpoint-162/special_tokens_map.json\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/run-9/checkpoint-144] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "\u001b[32m[I 2022-11-28 12:05:47,275]\u001b[0m Trial 9 pruned. \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calling best run\n",
        "best_run"
      ],
      "metadata": {
        "id": "X1agcFogmYQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ad04f1f-bf8f-48e4-d31a-b4132e2e0e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='0', objective=2.595929793216958, hyperparameters={'learning_rate': 1.0211178508623191e-06, 'weight_decay': 0.0035668865310456033})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnWYUwwkYOpW"
      },
      "source": [
        "# Initializing fine-tuning with parameters from hyperparameter search\n",
        "The below loop trains the model 10 times and saves the results from each training. This is due to langauge models being stochastic, so taking the average performance of 10 runs gives a more accurate estimate of performance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=tokenized_datasets[\"train\"],\n",
        "      eval_dataset=tokenized_datasets[\"test\"],\n",
        "      compute_metrics=compute_metrics,\n",
        "      callbacks = [early_stop])\n",
        "\n",
        "  for n, v in best_run.hyperparameters.items():\n",
        "      setattr(trainer.args, n, v) # for running the experiment with the best hyperparameters from the hyperparameters search\n",
        "\n",
        "  trainer.train() # argument trial can be used for hyperparameter search\n",
        "\n",
        "  trainer.evaluate()\n",
        "\n",
        "  import tensorflow as tf\n",
        "\n",
        "  # creating model predictions for the validation data\n",
        "  predictions_val = trainer.predict(tokenized_datasets[\"valid\"])\n",
        "\n",
        "  # choosing the prediction that has the highest probability \n",
        "  preds_val_val = np.argmax(predictions_val.predictions, axis=-1)\n",
        "\n",
        "  # calculating the probabilities instead of logits from each\n",
        "  predictions_probabilities = tf.nn.softmax(predictions_val.predictions)\n",
        "\n",
        "  def compute_metrics_end(preds, refs):\n",
        "      metric0 = evaluate.load(\"accuracy\")\n",
        "      metric1 = evaluate.load(\"precision\")\n",
        "      metric2 = evaluate.load(\"recall\")\n",
        "      metric3 = evaluate.load(\"f1\")\n",
        "      \n",
        "      #logits, labels = eval_pred\n",
        "      #predictions = np.argmax(logits, axis=-1)\n",
        "      accuracy = metric0.compute(predictions=preds, references=refs)[\"accuracy\"]\n",
        "      precision = metric1.compute(predictions=preds, references=refs, average=\"weighted\")[\"precision\"]\n",
        "      recall = metric2.compute(predictions=preds, references=refs, average=\"weighted\")[\"recall\"]\n",
        "      f1 = metric3.compute(predictions=preds, references=refs, average=\"weighted\")[\"f1\"]\n",
        "      return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "  metrics_val = compute_metrics_end(preds=preds_val_val, refs=predictions_val.label_ids)\n",
        "\n",
        "  import tensorflow as tf\n",
        "\n",
        "  # creating model predictions for the validation data\n",
        "  predictions_test = trainer.predict(tokenized_datasets[\"test\"])\n",
        "\n",
        "  # choosing the prediction that has the highest probability \n",
        "  preds_test_test = np.argmax(predictions_test.predictions, axis=-1)\n",
        "\n",
        "  # calculating the probabilities instead of logits from each\n",
        "  predictions_probabilities_test = tf.nn.softmax(predictions_test.predictions)\n",
        "\n",
        "  metrics_test = compute_metrics_end(preds=preds_test_test, refs=predictions_test.label_ids)\n",
        "\n",
        "  import pandas as pd\n",
        "\n",
        "  data = {'Predicted Labels': [\"negative\" if i == 0 else \"neutral\" if i == 1 else \"positive\" for i in preds_val_val],\n",
        "          'True Labels': [\"negative\" if i == 0 else \"neutral\" if i == 1 else \"positive\" for i in predictions_val.label_ids],\n",
        "          'Misclassification': [\"TRUE\" if preds_val_val[i] == predictions_val.label_ids[i] else 'MISS' for i, val in enumerate(preds_val_val)],\n",
        "          'Text': dataset_recombined['valid']['text'],\n",
        "          'Logit Values': [str(i) for i in predictions_val.predictions],\n",
        "          'Probabilities': [str(i) for i in np.asarray(predictions_probabilities)]}\n",
        "  df = pd.DataFrame(data)\n",
        "  df_metrics_val = pd.DataFrame(metrics_val.items())\n",
        "  df_metrics_test = pd.DataFrame(metrics_test.items())\n",
        "\n",
        "  df.to_csv(f\"/content/drive/MyDrive/BA_data/nbailab/df_classification_report{i}.csv\")\n",
        "  df_metrics_val.to_csv(f\"/content/drive/MyDrive/BA_data/nbailab/df_classification_metrics_val{i}.csv\")\n",
        "  df_metrics_test.to_csv(f\"/content/drive/MyDrive/BA_data/nbailab/df_classification_metrics_test{i}.csv\")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "eece768f71574ef6a661cfe29be433b0",
            "bd9d9250ed044ac997dcc5ac58577633",
            "5f7c5bb9dcb34a49ab1c49ab365c1651",
            "5a9b99be2743494cb304e21b23fbb50d",
            "fa4acdd362eb4e269e451df8a2c02fba",
            "0bd40cfadd3e487ba56c35088acc7a77",
            "61641cdb69664409af01ccef385296b9",
            "9e237a7b5e01474faf4f9151aa39594e"
          ]
        },
        "id": "sR5zEsTidz5e",
        "outputId": "79c73ceb-0d7f-45c4-b9fa-c173c713050c"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 180/3600 08:15 < 2:38:40, 0.36 it/s, Epoch 10/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.616209</td>\n",
              "      <td>0.658793</td>\n",
              "      <td>0.670291</td>\n",
              "      <td>0.658793</td>\n",
              "      <td>0.661832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.611414</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.673999</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.672767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.638412</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671111</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.674264</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671023</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.670918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.703730</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.675233</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.675121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.726892</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673049</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.745444</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675593</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.774629</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675461</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.793698</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674472</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.819797</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668465</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668685</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-18] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-180\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-180/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-180/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-36 (score: 1.6114144325256348).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='42' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  42/3600 01:47 < 2:38:51, 0.37 it/s, Epoch 2.28/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.642041</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.679075</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.678756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.695572</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.672987</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673445</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-180] due to args.save_total_limit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:28 < 2:40:27, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.642041</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.679075</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.678756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.695572</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.672987</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.738270</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673263</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.778500</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667720</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.792992</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.670668</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.670814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.802612</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.676864</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.677385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.812596</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.676836</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.677396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.840160</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674441</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.856600</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673284</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.6420413255691528).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:33 < 2:42:33, 0.35 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.708058</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.677523</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.677306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.768358</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671305</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.791520</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.672987</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.825149</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666315</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.665536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.836949</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.669722</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.669480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.837024</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675593</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.843356</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.676813</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.677413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.869613</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675551</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.885252</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675551</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.7080577611923218).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:29 < 2:41:03, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.792211</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.672782</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.671370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.833226</td>\n",
              "      <td>0.665354</td>\n",
              "      <td>0.665255</td>\n",
              "      <td>0.665354</td>\n",
              "      <td>0.664519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.837805</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674472</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.868113</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668808</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.878737</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667606</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.875308</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675551</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.877509</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.676905</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.677469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.901990</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675551</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.916203</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675669</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.7922112941741943).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:31 < 2:41:34, 0.35 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.841328</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.670145</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.668769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.874260</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.668250</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.879728</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673130</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.905888</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666002</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.665899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.916048</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666529</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.909873</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.669251</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.669750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.907953</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674125</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.928145</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.672894</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.940620</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674563</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.675029</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.8413281440734863).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:31 < 2:41:43, 0.35 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.878359</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.672524</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.671338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.909589</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.668293</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.919950</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.669495</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.669714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.935300</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666002</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.665899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.942691</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667405</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.936604</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.670731</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.931325</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.676688</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.677357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.949004</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674165</td>\n",
              "      <td>0.675853</td>\n",
              "      <td>0.674759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.960617</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.671909</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.672391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.8783588409423828).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:31 < 2:41:47, 0.35 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.909895</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.676090</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.675194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.937727</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.671232</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.670626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.955168</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666109</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.960753</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667513</td>\n",
              "      <td>0.667979</td>\n",
              "      <td>0.667340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.967935</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668858</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668793</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.963429</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.671909</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.672391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.957422</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675356</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.973472</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.672701</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.673332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.986351</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668236</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.9098949432373047).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:31 < 2:41:43, 0.35 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.937043</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.681003</td>\n",
              "      <td>0.679790</td>\n",
              "      <td>0.680334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.960954</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.675122</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.674759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.984301</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666585</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.984695</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666116</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.665987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.988836</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668730</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.983042</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.670898</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.971852</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.675906</td>\n",
              "      <td>0.677165</td>\n",
              "      <td>0.676435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.985535</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.677071</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.677632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.998818</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671056</td>\n",
              "      <td>0.671916</td>\n",
              "      <td>0.671293</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.9370430707931519).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:30 < 2:41:11, 0.36 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.968036</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.679570</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.678974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.991967</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.675302</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.674861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.010931</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666585</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.009233</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666030</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.665996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.019124</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666887</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.012761</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.668927</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.669054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.997847</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.672706</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.672953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.009840</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.672706</td>\n",
              "      <td>0.673228</td>\n",
              "      <td>0.672953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.034338</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.670207</td>\n",
              "      <td>0.669291</td>\n",
              "      <td>0.669681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.9680355787277222).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 2283\n",
            "  Num Epochs = 200\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3600\n",
            "  Number of trainable parameters = 355090435\n",
            "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='162' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 162/3600 07:32 < 2:41:55, 0.35 it/s, Epoch 9/200]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.993423</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.683739</td>\n",
              "      <td>0.682415</td>\n",
              "      <td>0.682954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.010260</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.679380</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.678869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.031716</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666418</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.030780</td>\n",
              "      <td>0.664042</td>\n",
              "      <td>0.663085</td>\n",
              "      <td>0.664042</td>\n",
              "      <td>0.663097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.047827</td>\n",
              "      <td>0.664042</td>\n",
              "      <td>0.664280</td>\n",
              "      <td>0.664042</td>\n",
              "      <td>0.663979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.047661</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.671228</td>\n",
              "      <td>0.670604</td>\n",
              "      <td>0.670892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.043708</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.680406</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.679259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.049685</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.679109</td>\n",
              "      <td>0.678478</td>\n",
              "      <td>0.678745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.070817</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.675105</td>\n",
              "      <td>0.674541</td>\n",
              "      <td>0.674809</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-18\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-18/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-18/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-36\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-36/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-36/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-162] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-54\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-54/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-54/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-36] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-72\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-72/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-72/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-54] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-90\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-90/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-90/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-72] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-108\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-108/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-108/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-90] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-126\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-126/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-126/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-108] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-144\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-144/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-144/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-126] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n",
            "Saving model checkpoint to NbAiLab/nb-bert-large/checkpoint-162\n",
            "Configuration saved in NbAiLab/nb-bert-large/checkpoint-162/config.json\n",
            "Model weights saved in NbAiLab/nb-bert-large/checkpoint-162/pytorch_model.bin\n",
            "Deleting older checkpoint [NbAiLab/nb-bert-large/checkpoint-144] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from NbAiLab/nb-bert-large/checkpoint-18 (score: 1.993422508239746).\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 761\n",
            "  Batch size = 128\n",
            "***** Running Prediction *****\n",
            "  Num examples = 762\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eece768f71574ef6a661cfe29be433b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁█▅▃▄▅▅▃▄▄▅▅▄▅▅▃▃▅▄▄▄▅▃▃▅▄▃▄▄▅▃▅▅▃▃▄▆▃▅▆</td></tr><tr><td>eval/f1</td><td>▁█▅▄▄▄▄▃▄▄▄▅▄▄▄▃▃▅▄▄▃▄▃▃▅▄▃▄▄▅▃▄▅▃▃▄▅▂▅▅</td></tr><tr><td>eval/loss</td><td>▂▁▄▄▅▅▆▆▅▆▆▅▆▆▇▆▇▇▆▇▇▇▇▇▇▇▇▇▇▇█▇▇███████</td></tr><tr><td>eval/precision</td><td>▁█▄▃▃▃▃▂▃▂▃▄▃▃▃▁▂▄▃▃▂▃▂▂▃▃▂▃▃▄▂▃▄▂▂▃▅▁▄▅</td></tr><tr><td>eval/recall</td><td>▁█▅▃▄▅▅▃▄▄▅▅▄▅▅▃▃▅▄▄▄▅▃▃▅▄▃▄▄▅▃▅▅▃▃▄▆▃▅▆</td></tr><tr><td>eval/runtime</td><td>▁▃▂▃▃▃▂▃▂▂▂▁▂▁▂▁▁▁▄▂▁▂▂█▁▂▃▂▁▃▁▂▃▂▂▂▄▂▂▄</td></tr><tr><td>eval/samples_per_second</td><td>█▆▇▆▆▆▇▆▇▇▇█▇█▇███▅▇█▇▇▁█▇▆▇█▆█▇▆▇▇▇▅▇▇▅</td></tr><tr><td>eval/steps_per_second</td><td>█▆▇▆▆▆▇▆▇▇▇█▇█▇███▅▇█▇▇▁█▇▆▇█▆█▇▆▇▇▇▅▇▇▅</td></tr><tr><td>train/epoch</td><td>▁▃▆█▃▅▇█▃▅▇▁▃▆▇▃▅▇▁▃▆▇▂▄▆▇▃▆▇▂▄▆▇▃▅▇▁▃▆▇</td></tr><tr><td>train/global_step</td><td>▁▃▆█▃▅▇█▃▅▇▁▃▆▇▃▅▇▁▃▆▇▂▄▆▇▃▆▇▂▄▆▇▃▅▇▁▃▆▇</td></tr><tr><td>train/total_flos</td><td>█▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/train_loss</td><td>█▅▄▃▃▃▃▂▂▁</td></tr><tr><td>train/train_runtime</td><td>█▁▂▁▁▂▂▂▁▂</td></tr><tr><td>train/train_samples_per_second</td><td>▁█▇█▇▇▇▇█▇</td></tr><tr><td>train/train_steps_per_second</td><td>▁█▇█▇▇▇▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.68241</td></tr><tr><td>eval/f1</td><td>0.68295</td></tr><tr><td>eval/loss</td><td>1.99342</td></tr><tr><td>eval/precision</td><td>0.68374</td></tr><tr><td>eval/recall</td><td>0.68241</td></tr><tr><td>eval/runtime</td><td>5.1456</td></tr><tr><td>eval/samples_per_second</td><td>148.087</td></tr><tr><td>eval/steps_per_second</td><td>1.166</td></tr><tr><td>train/epoch</td><td>9.0</td></tr><tr><td>train/global_step</td><td>162</td></tr><tr><td>train/total_flos</td><td>4787114605173504.0</td></tr><tr><td>train/train_loss</td><td>0.0122</td></tr><tr><td>train/train_runtime</td><td>454.124</td></tr><tr><td>train/train_samples_per_second</td><td>1005.452</td></tr><tr><td>train/train_steps_per_second</td><td>7.927</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">fast-fog-677</strong>: <a href=\"https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/43d8d8nj\" target=\"_blank\">https://wandb.ai/bachelor_thesis_cogsci/huggingface/runs/43d8d8nj</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20221128_115735-43d8d8nj/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "gVr_U-u5ZHLT"
      ],
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4d64efb679f4f6c9bc957bf1d2a00d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec975ed4c28443c6a4c8c0c5496498cf",
              "IPY_MODEL_a7322aff86f540dbb0066ad4f18ed8e6",
              "IPY_MODEL_d12d1ea10c15419a813bf3c430d6dd28"
            ],
            "layout": "IPY_MODEL_427c0def8d584fd987d290ebd2e7b650"
          }
        },
        "ec975ed4c28443c6a4c8c0c5496498cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbf16d5a7ec04015ba9c7bb1ebff0336",
            "placeholder": "​",
            "style": "IPY_MODEL_8faf336977ed494ca3c1dcbaef109655",
            "value": "100%"
          }
        },
        "a7322aff86f540dbb0066ad4f18ed8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cb41813b3224fb2b5122c95e7a797f4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5541bdc9c4d74ec5890158bb7d1db847",
            "value": 3
          }
        },
        "d12d1ea10c15419a813bf3c430d6dd28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa344af4be974b60a11ea862920394d7",
            "placeholder": "​",
            "style": "IPY_MODEL_d55c424af7004a0582428e1235087ecf",
            "value": " 3/3 [00:00&lt;00:00,  7.51ba/s]"
          }
        },
        "427c0def8d584fd987d290ebd2e7b650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf16d5a7ec04015ba9c7bb1ebff0336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8faf336977ed494ca3c1dcbaef109655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cb41813b3224fb2b5122c95e7a797f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5541bdc9c4d74ec5890158bb7d1db847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa344af4be974b60a11ea862920394d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d55c424af7004a0582428e1235087ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6c6071ac70864869b6a988659dcae17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba21747f291d40a09478442882f01972",
              "IPY_MODEL_b4480a2a4974450fa442f81ba6102fbf",
              "IPY_MODEL_6cd53cacb85540d49a77058b5d304fd9"
            ],
            "layout": "IPY_MODEL_8d08aca007eb433081904c0204310ef9"
          }
        },
        "ba21747f291d40a09478442882f01972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_813e4e29fcb54113909afdb3f6300d1b",
            "placeholder": "​",
            "style": "IPY_MODEL_5d45bc7e64004eb1b263c52c424c493d",
            "value": "100%"
          }
        },
        "b4480a2a4974450fa442f81ba6102fbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a238f5445874706a620834688236081",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8bed24945244a3b93a4b92eb85084ff",
            "value": 1
          }
        },
        "6cd53cacb85540d49a77058b5d304fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2175fcb9cec043288ff8e18ce34ed0ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6b4d4da70f444d188bad19b180a54c44",
            "value": " 1/1 [00:00&lt;00:00,  7.96ba/s]"
          }
        },
        "8d08aca007eb433081904c0204310ef9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "813e4e29fcb54113909afdb3f6300d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d45bc7e64004eb1b263c52c424c493d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a238f5445874706a620834688236081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8bed24945244a3b93a4b92eb85084ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2175fcb9cec043288ff8e18ce34ed0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b4d4da70f444d188bad19b180a54c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8120788d0f254f869d9d6b85e4cf2583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0162993232e4379ab6414aa3fa06ee3",
              "IPY_MODEL_19246bcafaaf488db3992e295b253d2a",
              "IPY_MODEL_5bb83b7b75a9419b98ed50e6665b5ab8"
            ],
            "layout": "IPY_MODEL_eb34ed630f1d47ea88899760831ab869"
          }
        },
        "d0162993232e4379ab6414aa3fa06ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37748dc2a29d4385893c6152857e88bb",
            "placeholder": "​",
            "style": "IPY_MODEL_506068e2c22f476da19d9f06cd8e92a1",
            "value": "100%"
          }
        },
        "19246bcafaaf488db3992e295b253d2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c58c228205847f78202c33f220aceef",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_224e7670a3c24c66957d1a8cb0cae2e0",
            "value": 1
          }
        },
        "5bb83b7b75a9419b98ed50e6665b5ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_769bf522f4264cb7a2b573d991432491",
            "placeholder": "​",
            "style": "IPY_MODEL_afabbfba35364718af1bd467fae32139",
            "value": " 1/1 [00:00&lt;00:00,  9.56ba/s]"
          }
        },
        "eb34ed630f1d47ea88899760831ab869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37748dc2a29d4385893c6152857e88bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "506068e2c22f476da19d9f06cd8e92a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c58c228205847f78202c33f220aceef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224e7670a3c24c66957d1a8cb0cae2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "769bf522f4264cb7a2b573d991432491": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afabbfba35364718af1bd467fae32139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fe0f7c9b7064037b1f54ee151a11c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fdd594589934f568d42be4c5d3dbaa8",
              "IPY_MODEL_8ad27001095b40a19f022ad90661098f"
            ],
            "layout": "IPY_MODEL_b4d3260684714ad2b1981cc92366f882"
          }
        },
        "0fdd594589934f568d42be4c5d3dbaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf932a6922f14b8cab6101c207195d61",
            "placeholder": "​",
            "style": "IPY_MODEL_5edb66fc85824b7684ea73d12cde8c41",
            "value": "0.011 MB of 0.011 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "8ad27001095b40a19f022ad90661098f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a88357d59b479db9e1e039fd23ae02",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0028181811e04e5abb1e30d76139e320",
            "value": 0.9977005620848237
          }
        },
        "b4d3260684714ad2b1981cc92366f882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf932a6922f14b8cab6101c207195d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5edb66fc85824b7684ea73d12cde8c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19a88357d59b479db9e1e039fd23ae02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0028181811e04e5abb1e30d76139e320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "853764544e0d4420aaa141a9088553f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_261ce02885d9479597d52de092c0ce90",
              "IPY_MODEL_73540108250b4982bbeee9f82c755aa6",
              "IPY_MODEL_962875cceb45480f94802be1e6964753"
            ],
            "layout": "IPY_MODEL_e03797a995254624a7a0edc3a36361ae"
          }
        },
        "261ce02885d9479597d52de092c0ce90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c52e16075ac64f17abb5e5903391ce62",
            "placeholder": "​",
            "style": "IPY_MODEL_d81797e3876e47fcad5eb01741eb4a6a",
            "value": "Downloading builder script: 100%"
          }
        },
        "73540108250b4982bbeee9f82c755aa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f8479d2a6064a56816465eefbf411f2",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d84f336426474ea3bcc2f25f034e165e",
            "value": 4203
          }
        },
        "962875cceb45480f94802be1e6964753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca99171d241546528d85a9ccbdb565b9",
            "placeholder": "​",
            "style": "IPY_MODEL_124067acc9f74ebb9e40207e45c9c4b2",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 157kB/s]"
          }
        },
        "e03797a995254624a7a0edc3a36361ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52e16075ac64f17abb5e5903391ce62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81797e3876e47fcad5eb01741eb4a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f8479d2a6064a56816465eefbf411f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84f336426474ea3bcc2f25f034e165e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ca99171d241546528d85a9ccbdb565b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "124067acc9f74ebb9e40207e45c9c4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ce1136b7005499eb5229853a7cd9991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82273548e68c4e6e83869642525a4cbf",
              "IPY_MODEL_c96f95363b7c477cb8d8fb97618de3b2",
              "IPY_MODEL_dfad5157c4574b8597eda82ac5b629fb"
            ],
            "layout": "IPY_MODEL_6b36478599f840dc9604e07d8df831b0"
          }
        },
        "82273548e68c4e6e83869642525a4cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d6d4074cb544a597f022c234f90584",
            "placeholder": "​",
            "style": "IPY_MODEL_0ac58ae8bd0d489a90142e0e593ef089",
            "value": "Downloading builder script: 100%"
          }
        },
        "c96f95363b7c477cb8d8fb97618de3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b8bdd98df24d1db8f8d19055425811",
            "max": 7546,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20a8f0cab3314210a3459fdd725d7d23",
            "value": 7546
          }
        },
        "dfad5157c4574b8597eda82ac5b629fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97262b1264be4600934f1d1f7c16b12c",
            "placeholder": "​",
            "style": "IPY_MODEL_7020c58d20754f9984ceae5506589e2e",
            "value": " 7.55k/7.55k [00:00&lt;00:00, 298kB/s]"
          }
        },
        "6b36478599f840dc9604e07d8df831b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97d6d4074cb544a597f022c234f90584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ac58ae8bd0d489a90142e0e593ef089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8b8bdd98df24d1db8f8d19055425811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a8f0cab3314210a3459fdd725d7d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97262b1264be4600934f1d1f7c16b12c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7020c58d20754f9984ceae5506589e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f91ade997acf49adafe9f412d3c185a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dabbd7a966534ad88e8b95c0d7be4514",
              "IPY_MODEL_46a1903d35574062bcacb61acdd468c6",
              "IPY_MODEL_1ad75ab7e3394b1f89571ebe9a8699c8"
            ],
            "layout": "IPY_MODEL_e0917cf144fb4f64ba6dd9f02c4691ff"
          }
        },
        "dabbd7a966534ad88e8b95c0d7be4514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1322e23024ce471db68239cbcd4f4f22",
            "placeholder": "​",
            "style": "IPY_MODEL_e59de640b5d3442c8cdee0081578ae79",
            "value": "Downloading builder script: 100%"
          }
        },
        "46a1903d35574062bcacb61acdd468c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f087d619835449d9ee8d9ce6a7e1b73",
            "max": 7363,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16923cb777024d8b81cb6dc49d1de632",
            "value": 7363
          }
        },
        "1ad75ab7e3394b1f89571ebe9a8699c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0f6739084a64185a5243dac7c1651ac",
            "placeholder": "​",
            "style": "IPY_MODEL_e5562c769c6a4180a776692a47e8699b",
            "value": " 7.36k/7.36k [00:00&lt;00:00, 279kB/s]"
          }
        },
        "e0917cf144fb4f64ba6dd9f02c4691ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1322e23024ce471db68239cbcd4f4f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e59de640b5d3442c8cdee0081578ae79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f087d619835449d9ee8d9ce6a7e1b73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16923cb777024d8b81cb6dc49d1de632": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0f6739084a64185a5243dac7c1651ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5562c769c6a4180a776692a47e8699b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a2eb32309374a23aa121c4d0101b350": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98de1fc212d547d6a366b0ba6226d8b8",
              "IPY_MODEL_18ab160427dc4d6e855316ff199fca4e",
              "IPY_MODEL_e942179f22de4b75a77f7cc2306f9569"
            ],
            "layout": "IPY_MODEL_5cad0b047d4b469e927a315bf516c397"
          }
        },
        "98de1fc212d547d6a366b0ba6226d8b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2aabf5feb2e42478307ec7de2618f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_46dcac2dc82b415c83f6a9287537b063",
            "value": "Downloading builder script: 100%"
          }
        },
        "18ab160427dc4d6e855316ff199fca4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd9a1d6a0cbd4f5ab5d483c9d7d36451",
            "max": 6771,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd894aed81a14478ab577238ea678dce",
            "value": 6771
          }
        },
        "e942179f22de4b75a77f7cc2306f9569": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f33ab1a87114df7b99c8277eaf730d9",
            "placeholder": "​",
            "style": "IPY_MODEL_78cc5fba74eb4326b8324f1be7e51dce",
            "value": " 6.77k/6.77k [00:00&lt;00:00, 255kB/s]"
          }
        },
        "5cad0b047d4b469e927a315bf516c397": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2aabf5feb2e42478307ec7de2618f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46dcac2dc82b415c83f6a9287537b063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd9a1d6a0cbd4f5ab5d483c9d7d36451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd894aed81a14478ab577238ea678dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f33ab1a87114df7b99c8277eaf730d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78cc5fba74eb4326b8324f1be7e51dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f71976fdfbb4e7f83b9a30561d5134e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4054e2e7a7a940a981b5eafff3c0ab50",
              "IPY_MODEL_045dd63f50e54a18b0e89c33c2375b8b"
            ],
            "layout": "IPY_MODEL_f89792972e644c4b8619f73a727a1b16"
          }
        },
        "4054e2e7a7a940a981b5eafff3c0ab50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e51054406a094f67918b5527555ef0f9",
            "placeholder": "​",
            "style": "IPY_MODEL_c19adb48150e4765a11721835f41c483",
            "value": "0.001 MB of 0.760 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "045dd63f50e54a18b0e89c33c2375b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1feb402b739e4120913dd85f82666bcc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd5894d462ad439d84178480559259c4",
            "value": 0.0009694333768512352
          }
        },
        "f89792972e644c4b8619f73a727a1b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51054406a094f67918b5527555ef0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19adb48150e4765a11721835f41c483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1feb402b739e4120913dd85f82666bcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5894d462ad439d84178480559259c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f00d455158844c88b8903cd0c49a5146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc1fdba7f8234aa499ee91ef5a73fbeb",
              "IPY_MODEL_6068e6c1bff245858ffa5362ec61767f"
            ],
            "layout": "IPY_MODEL_cf7b154576094abdb4928482661fcd5c"
          }
        },
        "fc1fdba7f8234aa499ee91ef5a73fbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd24d85d8f0b4b3d864fe7d3c522b0d2",
            "placeholder": "​",
            "style": "IPY_MODEL_8b91cc1c7044483b9ca87cc286b581c2",
            "value": "0.001 MB of 0.874 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "6068e6c1bff245858ffa5362ec61767f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_685420bc83cd45d7b5c2bd358fee60b1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_223cbc62f23641fb889b279e8be66406",
            "value": 0.0008449726311836385
          }
        },
        "cf7b154576094abdb4928482661fcd5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd24d85d8f0b4b3d864fe7d3c522b0d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b91cc1c7044483b9ca87cc286b581c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "685420bc83cd45d7b5c2bd358fee60b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "223cbc62f23641fb889b279e8be66406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5405b644fbf84a1ebe1b9755ac2d1de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9db43243b5d473780ce9b143375af54",
              "IPY_MODEL_9f2d3f553e9a4447baa75d3f5b5d4480"
            ],
            "layout": "IPY_MODEL_544a75140be84366afbe69465449f804"
          }
        },
        "c9db43243b5d473780ce9b143375af54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db34d709d47e4b468ab92059d48e1eb8",
            "placeholder": "​",
            "style": "IPY_MODEL_577269151bae497f90911eee99f438f4",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9f2d3f553e9a4447baa75d3f5b5d4480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba20317cda604df497d8675e7207218d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a5975553bef45099864bd905d902f17",
            "value": 1
          }
        },
        "544a75140be84366afbe69465449f804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db34d709d47e4b468ab92059d48e1eb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577269151bae497f90911eee99f438f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba20317cda604df497d8675e7207218d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a5975553bef45099864bd905d902f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7589dafc0e334d40ae64016d2ae58020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10903f19a84249459f87a7c8fe458f7f",
              "IPY_MODEL_736fa318528a4d82822aa063ff80d4de"
            ],
            "layout": "IPY_MODEL_72669b70d21a47a4bb9f80661b1c2ac4"
          }
        },
        "10903f19a84249459f87a7c8fe458f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f909cb1b6f64e68b48912df90394aee",
            "placeholder": "​",
            "style": "IPY_MODEL_40cc824de5c54e119190df8e0e6e4eb8",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "736fa318528a4d82822aa063ff80d4de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e36cd971a314d909d1616aa68e0b971",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17bde09e8f744c2da8ebfc3c099ce18c",
            "value": 1
          }
        },
        "72669b70d21a47a4bb9f80661b1c2ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f909cb1b6f64e68b48912df90394aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40cc824de5c54e119190df8e0e6e4eb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e36cd971a314d909d1616aa68e0b971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17bde09e8f744c2da8ebfc3c099ce18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6184451e6954b22ba1fe6e9cce05c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4025501db924d929d31f6d66e90fccb",
              "IPY_MODEL_574caf6116ff42738839bcc732b4df8e"
            ],
            "layout": "IPY_MODEL_cfe30f200df74713869c9b0f52547c12"
          }
        },
        "b4025501db924d929d31f6d66e90fccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d54df4c9cef841269338ebfb5e1eea19",
            "placeholder": "​",
            "style": "IPY_MODEL_0fcf6dd35f9841849ccbeb9c6da74513",
            "value": "0.001 MB of 0.887 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "574caf6116ff42738839bcc732b4df8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e54b202a4ae480482013c58b3eeb11b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_490ec2ba7bad49919020be066921c6e4",
            "value": 0.0008317822492939523
          }
        },
        "cfe30f200df74713869c9b0f52547c12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54df4c9cef841269338ebfb5e1eea19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fcf6dd35f9841849ccbeb9c6da74513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e54b202a4ae480482013c58b3eeb11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490ec2ba7bad49919020be066921c6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5630d7b1e70c49f38d08069fe506e4cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c4f2a1703844325badabd20d7c55fab",
              "IPY_MODEL_0f6146b57dac4fdd9b19a11d2c922b46"
            ],
            "layout": "IPY_MODEL_153d2dbb2c384c96b4eaca4a97f3375b"
          }
        },
        "2c4f2a1703844325badabd20d7c55fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c91ced643d384bd9b01fed1f796315d8",
            "placeholder": "​",
            "style": "IPY_MODEL_2bc6c606397a420d9f739054f37086f5",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "0f6146b57dac4fdd9b19a11d2c922b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4bc5f04e8d741208d773c072494a675",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_854fea52a18d464587b59094c23b8da5",
            "value": 1
          }
        },
        "153d2dbb2c384c96b4eaca4a97f3375b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c91ced643d384bd9b01fed1f796315d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bc6c606397a420d9f739054f37086f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4bc5f04e8d741208d773c072494a675": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854fea52a18d464587b59094c23b8da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43132dc684674ce89e416d23f31bf3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3490d51978704deba7d72a1dab2e8963",
              "IPY_MODEL_35023f9311304efd8a66164c2bc2fd49"
            ],
            "layout": "IPY_MODEL_035033128a00458db2982bd7caf21ab0"
          }
        },
        "3490d51978704deba7d72a1dab2e8963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a02d7a22c1df42ffa51bb0a51996c3de",
            "placeholder": "​",
            "style": "IPY_MODEL_4b0970aa19f14ddf910652af24959404",
            "value": "0.001 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "35023f9311304efd8a66164c2bc2fd49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39a4d04c6364ddb8eba1f009619348d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52421db347984b8881de97834d831e8e",
            "value": 0.04023767330345043
          }
        },
        "035033128a00458db2982bd7caf21ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a02d7a22c1df42ffa51bb0a51996c3de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b0970aa19f14ddf910652af24959404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b39a4d04c6364ddb8eba1f009619348d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52421db347984b8881de97834d831e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ad5f8d75eb74a87b502298a311c9f94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34462726cbe24d7c884ca323e69258c6",
              "IPY_MODEL_824a70f0935a44acb932d30f189d5144"
            ],
            "layout": "IPY_MODEL_a478337ed24d485786fa758c6d537244"
          }
        },
        "34462726cbe24d7c884ca323e69258c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d393091487e401eaef2c3430f339662",
            "placeholder": "​",
            "style": "IPY_MODEL_1564484b205f490e9898c147104a0a84",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "824a70f0935a44acb932d30f189d5144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b35a2b4922f34adaabd85a37aeeccb71",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8c7024d0c72442fba4074fce03aa7dad",
            "value": 1
          }
        },
        "a478337ed24d485786fa758c6d537244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d393091487e401eaef2c3430f339662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1564484b205f490e9898c147104a0a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35a2b4922f34adaabd85a37aeeccb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c7024d0c72442fba4074fce03aa7dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eece768f71574ef6a661cfe29be433b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd9d9250ed044ac997dcc5ac58577633",
              "IPY_MODEL_5f7c5bb9dcb34a49ab1c49ab365c1651"
            ],
            "layout": "IPY_MODEL_5a9b99be2743494cb304e21b23fbb50d"
          }
        },
        "bd9d9250ed044ac997dcc5ac58577633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4acdd362eb4e269e451df8a2c02fba",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd40cfadd3e487ba56c35088acc7a77",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5f7c5bb9dcb34a49ab1c49ab365c1651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61641cdb69664409af01ccef385296b9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e237a7b5e01474faf4f9151aa39594e",
            "value": 1
          }
        },
        "5a9b99be2743494cb304e21b23fbb50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4acdd362eb4e269e451df8a2c02fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd40cfadd3e487ba56c35088acc7a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61641cdb69664409af01ccef385296b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e237a7b5e01474faf4f9151aa39594e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}